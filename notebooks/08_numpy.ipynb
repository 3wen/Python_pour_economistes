{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à Numpy {#numpy}\n",
    "\n",
    "Ce chapitre est consacré à une librairie importante pour les calculs numérique : `NumPy` (abréviation de *Numerical Python*).\n",
    "\n",
    "Il est coutume d'importer `NumPy` en lui attribuant l'alias `np` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableaux {#numpy-tableaux}\n",
    "\n",
    "NumPy propose une structure de données populaire, les tableaux (de type *array*), sur lesquels il est possible d'effectuer de manière efficace des calculs. Les tableaux sont une structure notamment utile pour effectuer des opérations statistiques basiques ainsi que de la génération pseudo-aléatoire de nombres.\n",
    "\n",
    "La stucture des tableaux ressemble à celle des listes, mais ces dernières sont moins rapides à être traitées et utilisent davantage de mémoire. Le gain de vitesse de traitement des tableaux en `NumPy` vient du fait que les données sont stockées dans des blocs contigus de mémoire, facilitant ainsi les accès en lecture.\n",
    "\n",
    "Pour s'en convaincre, on peut reprendre l'exemple de Pierre Navaro [donné dans son *notebook* sur `NumPy`](https://github.com/pnavaro/python-notebooks/blob/master/13.Numpy.ipynb). Créons deux listes de longueur 1000 chacune, avec des nombres tirés aléatoirement à l'aide de la fonction `random()` du module `random`. Divisons chaque élément de la première liste par l'élément à la même position dans la seconde ligne, puis calculons la somme de ces 1000 divisions. Regardons ensuite le temps d'exécution à l'aide de la fonction magique `%timeit` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from operator import truediv\n",
    "l1 = [random() for i in range(1000)]\n",
    "l2 = [random() for i in range(1000)]\n",
    "# %timeit s = sum(map(truediv,l1,l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(décommenter la dernière ligne et tester sur un Jupyter Notebook)\n",
    "\n",
    "À présent, transformons les deux listes en tableaux `NumPy` avec la méthode `array()`, et effectuons le même calcul à l'aide d'une méthode `NumPy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array(l1)\n",
    "a2 = np.array(l2)\n",
    "# %timeit s = np.sum(a1/a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le constater en exécutant ces codes dans un environnement IPython, le temps d'exécution est bien plus rapide avec les méthodes de `NumPy` pour ce calcul.\n",
    "\n",
    "### Création\n",
    "\n",
    "La création d'un tableau peut s'effectuer avec la méthode `array()`, à partir d'une liste, comme nous venon de le faire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = [1,2,4]\n",
    "tableau = np.array(liste)\n",
    "print(tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [1 2 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tableau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on fournit à `array()` une liste de listes imbriquées de même longueur, un tableau multidimensionnel sera créé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_2 = [ [1,2,3], [4,5,6] ]\n",
    "tableau_2 = np.array(liste_2)\n",
    "print(tableau_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[1 2 3]\n",
    "##  [4 5 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tableau_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tableaux peuvent aussi être créés à partir de n-uplets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuplet = (1, 2, 3)\n",
    "tableau = np.array(nuplet)\n",
    "print(tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [1 2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tableau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tableau en dimension 1 peut être changé en tableau en dimension 2 (si possible), en modifiant son attribut `shape` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau = np.array([3, 2, 5, 1, 6, 5])\n",
    "tableau.shape = (3,2)\n",
    "print(tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[3 2]\n",
    "##  [5 1]\n",
    "##  [6 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelques fonctions générant des `array`\n",
    "\n",
    "Certaines fonctions de `NumPy` produisent des tableaux pré-remplis. C'est le cas de la fonction `zeros()`. Quand on lui fournit une valeur entière $n$, la fonction `zeros()` créé un tableau à une dimension, avec $n$ 0 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.zeros(4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut préciser le type des zéros (par exemple `int`, `int32`, `int64`, `float`, `float32`, `float64`, etc.), à l'aide du paramètre `dtype` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.zeros(4, dtype = \"int\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [0 0 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'avantage d'explications sur les types de données avec `NumPy` sont disponibles [sur la documentation en ligne](https://docs.scipy.org/doc/numpy-1.15.1/reference/arrays.dtypes.html).\n",
    "\n",
    "\n",
    "Le type des éléments d'un tableau est indiqué dans l'attribut `dtype` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(4, dtype = \"int\")\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [0 0 0 0] int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est par ailleurs possible de convertir le type des éléments dans un un autre type, à l'aide de la méthode `astype()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.astype(\"float\")\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [0 0 0 0] int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [0. 0. 0. 0.] float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand on lui fournit un n-uplet de longueur supérieure à 1, `zeros()` créé un tableau à plusieurs dimensions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.zeros((2, 3)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[0. 0. 0.]\n",
    "##  [0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.zeros((2, 3, 4)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[[0. 0. 0. 0.]\n",
    "##   [0. 0. 0. 0.]\n",
    "##   [0. 0. 0. 0.]]\n",
    "## \n",
    "##  [[0. 0. 0. 0.]\n",
    "##   [0. 0. 0. 0.]\n",
    "##   [0. 0. 0. 0.]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `empty()` de `Numpy` retourne également un tableau sur le même principe que `zeros()`, mais sans initialiser les valeurs à l'intérieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.empty((2, 3), dtype = \"int\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[0 0 0]\n",
    "##  [0 0 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `ones()` de `Numpy` retourne le même genre de tableaux, avec des 1 en valeurs initialisées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.ones((2, 3), dtype = \"float\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[1. 1. 1.]\n",
    "##  [1. 1. 1.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour choisir une valeur spécifique pour l'initialisation, on peut utiliser la fonction `full()` de `Numpy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.full((2, 3), 10, dtype = \"float\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[10. 10. 10.]\n",
    "##  [10. 10. 10.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.full((2, 3), np.inf) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[inf inf inf]\n",
    "##  [inf inf inf]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `eye()` de `Numpy` créé un tableau à deux dimensions dans laquelle tous les éléments sont initalisés à zéro, sauf ceux de la diagonale initialisés à 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.eye(2, dtype=\"int64\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[1 0]\n",
    "##  [0 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En modifiant le paramètre mot-clé `k`, on peut décaler la diagonale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.eye(3, k=-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[0. 0. 0.]\n",
    "##  [1. 0. 0.]\n",
    "##  [0. 1. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `identity()` de `Numpy` créé quant à elle une matrice identité sous la forme d'un tableau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.identity(3, dtype = \"int\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[1 0 0]\n",
    "##  [0 1 0]\n",
    "##  [0 0 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `arange()` de `Numpy` permet de générer une séquence de nombres séparés par un interval fixe, le tout stocké dans un tableau. La syntaxe est la suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange( start, stop, step, dtype )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avec `start` la valeur de départ, `stop` celle d'arrivée, `step` le pas, l'espacement entre les nombres de la séquence et `dtype` le type des nombres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.arange(5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [0 1 2 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.arange(2, 5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [2 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.arange(2, 10, 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [2 4 6 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions\n",
    "\n",
    "Pour connaître la dimension d'un tableau, on peut afficher la valeur de l'attribut `ndim` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ndim tableau : \", tableau.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ndim tableau :  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ndim tableau_2 : \", tableau_2.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ndim tableau_2 :  2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'éléments dans le tableau peut s'obtenir par l'attribut `size` ou par la fonction `size()` de `Numpy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size tableau : \", tableau.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## size tableau :  6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size tableau_2 : \", tableau_2.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## size tableau_2 :  6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"np.size(tableau) :\", np.size(tableau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## np.size(tableau) : 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'attribut `shape` retourne un n-uplet indiquant la longueur pour chaque dimension du tableau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size tableau : \", tableau.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## size tableau :  (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size tableau_2 : \", tableau_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## size tableau_2 :  (2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des éléments d'un tableau\n",
    "\n",
    "L'accès aux éléments d'un tableau se fait de la même manière que pour les listes  (c.f. Section\\ \\@ref(stucture-liste-extraction)), grâce à l'indiçage. La syntaxe est la suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau[lower:upper:step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avec `lower` la borne inférieur de la plage d'indices, `upper` la plage supérieur, et `step` l'espacement entre les valeurs.\n",
    "\n",
    "- Lorsque `lower` n'est pas précisé, le premier élément (indicé 0) est considéré comme la valeur attribuée à `lower`.\n",
    "- Lorsque `upper` n'est pas précisé, le dernier élément est considéré comme la valeur attribuée à `upper`.\n",
    "- Lorsque `step` n'est pas précisé, un pas de 1 est attribué par défaut.\n",
    "\n",
    "Reprenons rapidement quelques exemples, en s'appuyant sur deux objets : un tableau de dimension 1, et un second de dimension 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_1 = np.arange(1,13)\n",
    "tableau_2 = [ [1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "tableau_2 = np.array(tableau_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accès au premier élément :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"tableau_{}[0] : {} (type : {})\"\n",
    "print(message.format(0, tableau_1[0], type(tableau_1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_0[0] : 1 (type : <class 'numpy.int64'>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message.format(1, tableau_2[0], type(tableau_2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_1[0] : [1 2 3] (type : <class 'numpy.ndarray'>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accès aux éléments peut se faire en partant par la fin :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tableau_1[-1] : \", tableau_1[-1]) # dernier élément"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_1[-1] :  12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tableau_2[-1] : \", tableau_2[-1]) # dernier élément"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_2[-1] :  [10 11 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le découpage est possible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les éléments du 2e (non inclus) au 4e\n",
    "print(\"Slice Tableau 1 : \\n\", tableau_1[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Slice Tableau 1 : \n",
    "##  [3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sclie Tableau 2 : \\n\", tableau_2[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sclie Tableau 2 : \n",
    "##  [[ 7  8  9]\n",
    "##  [10 11 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les tableaux à deux dimensions, on peut accéder aux éléments de la manière suivante, de manière équivalente :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans le 3e élément, accéder au 1er élément\n",
    "print(tableau_2[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tableau_2[2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour extraire des colonnes d'un tableau à deux entrées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deuxième colonne : \\n\", tableau_2[:, [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deuxième colonne : \n",
    "##  [[ 2]\n",
    "##  [ 5]\n",
    "##  [ 8]\n",
    "##  [11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deuxièmes et troisièmes colonnes : \\n\", tableau_2[:, [1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deuxièmes et troisièmes colonnes : \n",
    "##  [[ 2  3]\n",
    "##  [ 5  6]\n",
    "##  [ 8  9]\n",
    "##  [11 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette dernière instruction, on indique avec le premier paramètre non renseigné (avant les deux points) que l'on désire tous les éléments de la première dimension, puis, avec la virgule, on indique qu'on regarde à l'intérieur de chaque élément de la première dimension, et qu'on veut les valeurs aux positions 1 et 2 (donc les éléments des colonnes 2 et 3).\n",
    "\n",
    "\n",
    "Pour extraire seulement certains éléments d'un tableau à 1 dimension, on peut indiquer les indices des éléments à récupérer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2e et 4e éléments : \\n\", tableau_2[[1,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2e et 4e éléments : \n",
    "##  [[ 4  5  6]\n",
    "##  [10 11 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction à l'aide de booléens\n",
    "\n",
    "\n",
    "Pour extraire ou non des éléments d'un tableu, on peut utiliser des tableaux de booléens en tant que masques. L'idée est de fournir un tableau de booléens (un masque) de même dimension que celui pour lequel on désire extraire des éléments sous certaines conditions. Lorsque la valeur du booléen dans le masque vaut `True`, l'élément correspondant du tableau est retourné ; sinon, il ne l'est pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau = np.array([0, 3, 2, 5, 1, 4])\n",
    "res = tableau[[True, False, True, False, True, True]]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [0 2 1 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seuls les éléments en position 1, 3, 5 et 6 on été retournés.\n",
    "\n",
    "En pratique, le masque n'est que très rarement créé par l'utilisateur, il est plutôt issu d'une instruction logique appliquée au tableau d'intérêt. Par exemple, dans notre tableau, nous pouvons dans un premier temps créer un masque de manière à identifier les éléments pairs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masque = tableau % 2 == 0\n",
    "print(masque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [ True False  True False False  True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(masque))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois ce masque créé, on peut l'appliquer au tableau pour extraire uniquement les éléments pour lesquels la valeur correspondante dans le masque vaut `True` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tableau[masque])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [0 2 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification\n",
    "\n",
    "Pour remplacer les valeurs d'un tableau, on utilise le signe égal (`=`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau = np.array([ [1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "tableau[0] = [11, 22, 33]\n",
    "print(tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[11 22 33]\n",
    "##  [ 4  5  6]\n",
    "##  [ 7  8  9]\n",
    "##  [10 11 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on fournit un scalaire lors du remplacement, la valeur sera répétée pour tous les éléments de la dimension :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau[0] = 100\n",
    "print(tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[100 100 100]\n",
    "##  [  4   5   6]\n",
    "##  [  7   8   9]\n",
    "##  [ 10  11  12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idem avec un découpage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau[0:2] = 100\n",
    "print(tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[100 100 100]\n",
    "##  [100 100 100]\n",
    "##  [  7   8   9]\n",
    "##  [ 10  11  12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'ailleurs, un découpage avec juste les deux points sans préciser les paramètres de début et de fin du découpage suivi d'un signe égal et d'un nombre remplace toutes les valeurs du tableau par ce nombre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau[:] = 0\n",
    "print(tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[0 0 0]\n",
    "##  [0 0 0]\n",
    "##  [0 0 0]\n",
    "##  [0 0 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout d'éléments\n",
    "\n",
    "Pour ajouter des éléments, on utilise la fonction `append()` de `NumPy`. Il faut noter que l'appel à cette fonction ne modifie pas l'objet auquel on ajoute les valeurs. Si on désire que les modifications sont apportées à cet objet, il faut l'écraser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = np.array([1,3,5])\n",
    "print(\"t_1 : \", t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 :  [1 3 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = np.append(t_1, 1)\n",
    "print(\"t_1 après l'ajout : \", t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 après l'ajout :  [1 3 5 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ajouter une colonne à un tableau à deux dimensions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_2 = np.array([[1,2,3], [5,6,7]])\n",
    "print(\"t_2 : \\n\", t_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_2 : \n",
    "##  [[1 2 3]\n",
    "##  [5 6 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_col_t_2 = np.array([[4], [8]])\n",
    "t_2 = np.append(t_2,ajout_col_t_2, axis = 1)\n",
    "print(\"t_2 après ajout colonne : \\n\", t_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_2 après ajout colonne : \n",
    "##  [[1 2 3 4]\n",
    "##  [5 6 7 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ajouter une ligne, on utilise la fonction `vstack()` de `Numpy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajout_ligne_t_2 = np.array([10, 11, 12, 13])\n",
    "t_2 = np.vstack([t_2,ajout_ligne_t_2])\n",
    "print(\"t_2 après ajout ligne : \\n\", t_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_2 après ajout ligne : \n",
    "##  [[ 1  2  3  4]\n",
    "##  [ 5  6  7  8]\n",
    "##  [10 11 12 13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression d'éléments\n",
    "\n",
    "Pour supprimer des éléments, on utilise la fonction `delete()` de `NumPy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_1 : \", t_1)\n",
    "# Supprimer le dernier élément"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 :  [1 3 5 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(t_1, (-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : pour que la suppression soit effective, on assigne le résultat de `np.delete()` à l'objet.\n",
    "\n",
    "Pour supprimer plusieurs éléments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_1 : \", t_1)\n",
    "# Supprimer les 1er et 2e éléments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 :  [1 3 5 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = np.delete(t_1, ([0, 2]))\n",
    "print(t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [3 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour supprimer une colonne d'un tableau à deux dimensions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_2 : \", t_2)\n",
    "# Supprimer la première colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_2 :  [[ 1  2  3  4]\n",
    "##  [ 5  6  7  8]\n",
    "##  [10 11 12 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(t_2, (0), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer plusieurs colonnes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_2 : \", t_2)\n",
    "# Supprimer la 1ère et la 3e colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_2 :  [[ 1  2  3  4]\n",
    "##  [ 5  6  7  8]\n",
    "##  [10 11 12 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(t_2, ([0,2]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et pour supprimer une ligne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_2 : \", t_2)\n",
    "# Supprimer la première ligne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_2 :  [[ 1  2  3  4]\n",
    "##  [ 5  6  7  8]\n",
    "##  [10 11 12 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(t_2, (0), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer plusieurs lignes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_2 : \", t_2)\n",
    "# Supprimer la 1ère et la 3e ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_2 :  [[ 1  2  3  4]\n",
    "##  [ 5  6  7  8]\n",
    "##  [10 11 12 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(t_2, ([0,2]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copie de tableau\n",
    "\n",
    "La copie d'un tableau, comme pour les listes (c.f. Section\\ \\@ref(copie-de-liste)), ne doit pas se faire avec le symbole égal (`=`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_1 = np.array([1, 2, 3])\n",
    "tableau_2 = tableau_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifions le premier élément de `tableau_2`, et observons le contenu de `tableau_2` et de `tableau_1` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_2[0] = 0\n",
    "print(\"Tableau 1 : \\n\", tableau_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tableau 1 : \n",
    "##  [0 2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tableau 2 : \\n\", tableau_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tableau 2 : \n",
    "##  [0 2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le constater, le fait d'avoir utilisé le signe égal a simplement créé une référence et non pas une copie.\n",
    "\n",
    "Pour effectuer une copie de tableaux, plusieurs façons existent. Parmi elles, l'utilisation de la fonction `np.array()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_1 = np.array([1, 2, 3])\n",
    "tableau_2 = np.array(tableau_1)\n",
    "tableau_2[0] = 0\n",
    "print(\"tableau_1 : \", tableau_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_1 :  [1 2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tableau_2 : \", tableau_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_2 :  [0 2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également utiliser la méthode `copy()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_1 = np.array([1, 2, 3])\n",
    "tableau_2 = tableau_1.copy()\n",
    "tableau_2[0] = 0\n",
    "print(\"tableau_1 : \", tableau_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_1 :  [1 2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tableau_2 : \", tableau_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_2 :  [0 2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut noter que lorsque l'on fait un découpement, un nouvel objet est créé, pas une référence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_1 = np.array([1, 2, 3, 4])\n",
    "tableau_2 = tableau_1[:2]\n",
    "tableau_2[0] = 0\n",
    "print(\"tableau_1 : \", tableau_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_1 :  [0 2 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tableau_2 : \", tableau_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_2 :  [0 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri\n",
    "\n",
    "La librairie `NumPy` fournit une fonction pour trier les tableaux : `sort()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau = np.array([3, 2, 5, 1, 6, 5])\n",
    "print(\"Tableau trié : \", np.sort(tableau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tableau trié :  [1 2 3 5 5 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tableau : \", tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tableau :  [3 2 5 1 6 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le constater, la fonction `sort()` de `NumPy` propose une vue : le tableau n'est pas modifié, ce qui n'est  pas le cas si on utilise la méthode `sort()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau = np.array([3, 2, 5, 1, 6, 5])\n",
    "tableau.sort()\n",
    "print(\"Le tableau a été modifié : \", tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Le tableau a été modifié :  [1 2 3 5 5 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposition {#transposition-tableau}\n",
    "\n",
    "Pour obtenir la transposée d'un tableau, on fait appel à l'attribut `T`. Il faut noter que l'on obtient une vue de l'objet, que cela ne le modifie pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau = np.array([3, 2, 5, 1, 6, 5])\n",
    "tableau.shape = (3,2)\n",
    "print(\"Tableau : \\n\", tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tableau : \n",
    "##  [[3 2]\n",
    "##  [5 1]\n",
    "##  [6 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tableau transposé : \\n\", tableau.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tableau transposé : \n",
    "##  [[3 5 6]\n",
    "##  [2 1 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également utiliser la fonction `transpose()` de `NumPy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.transpose(tableau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[3 5 6]\n",
    "##  [2 1 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, si on assigne un nom à la transposée, que ce soit en utilisant l'attribut `T` ou la méthode `np.transpose()`, cela créé une référence, pas une copie d'élément..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_transpose = np.transpose(tableau)\n",
    "tableau_transpose[0,0] = 99\n",
    "print(\"tableau : \\n\", tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau : \n",
    "##  [[99  2]\n",
    "##  [ 5  1]\n",
    "##  [ 6  5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tableau_transpose : \\n\", tableau_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_transpose : \n",
    "##  [[99  5  6]\n",
    "##  [ 2  1  5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour savoir si un tableau est une vue ou non, on peut afficher l'attribut `base`, qui retourne `None` si ce n'est pas le cas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tableau : \", tableau.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau :  None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tableau_transpose : \", tableau_transpose.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tableau_transpose :  [[99  2]\n",
    "##  [ 5  1]\n",
    "##  [ 6  5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opérations sur les tableaux {#operations-tableaux}\n",
    "\n",
    "Il est possible d'utiliser des opérateurs sur les tableaux. Leur effet nécessite quelques explications.\n",
    "\n",
    "#### Opérateurs `+` et `-`\n",
    "\n",
    "Lorsque l'opérateur `+` (`-`) est utilisé entre deux tableaux de même dimension, une addition (soustraction) terme à terme est effectuée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = np.array([1, 2, 3, 4])\n",
    "t_2 = np.array([5, 6, 7, 8])\n",
    "t_3 = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "t_4 = np.array([[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]])\n",
    "t_1 + t_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_3 + t_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 - t_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque l'opérateur `+` (`-`) est utilisé entre un scalaire et un tableau, le scalaire est ajouté (soustrait) à tous les éléments du tableau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_1 + 3 : \\n\", t_1 + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 + 3 : \n",
    "##  [4 5 6 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_1 + 3. : \\n\", t_1 + 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 + 3. : \n",
    "##  [4. 5. 6. 7.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_3 + 3 : \\n\", t_3 + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_3 + 3 : \n",
    "##  [[ 4  5  6  7]\n",
    "##  [ 8  9 10 11]\n",
    "##  [12 13 14 15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_3 - 3 : \\n\", t_3 - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_3 - 3 : \n",
    "##  [[-2 -1  0  1]\n",
    "##  [ 2  3  4  5]\n",
    "##  [ 6  7  8  9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opérateurs `*` et `/`\n",
    "\n",
    "Lorsque l'opérateur `*` (`/`) est utilisé entre deux tableaux de même dimension, une multiplication (division) terme à terme est effectuée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 * t_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_3 * t_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_3 / t_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque l'opérateur `*` (`/`) est utilisé entre un scalaire et un tableau, tous les éléments du tableau sont multipliés (divisés) par ce scalaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_1 * 3 : \\n\", t_1 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 * 3 : \n",
    "##  [ 3  6  9 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_1 / 3 : \\n\", t_1 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 / 3 : \n",
    "##  [0.33333333 0.66666667 1.         1.33333333]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puissance\n",
    "\n",
    "Il est également possible d'élever chaque nombre d'un tableau à une puissance donnée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t_1 ** 3 : \\n\", t_1 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 ** 3 : \n",
    "##  [ 1  8 27 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opérations sur des matrices\n",
    "\n",
    "En plus des opérations/soustraction/multiplication/division terme à terme ou par un scalaire, il est possible d'effectuer certains calculs sur des tableaux à deux dimension.\n",
    "\n",
    "Nous avons déjà vu la tranposée en Section\\ \\@ref(transposition-tableau).\n",
    "\n",
    "Pour effectuer un produit matriciel, `NumPy` fournit la fonction `dot()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(t_3, t_4.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut bien s'assurer d'avoir des matrices compatibles, sinon, une erreur sera retournée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(t_3, t_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ValueError: shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)\n",
    "## \n",
    "## Detailed traceback: \n",
    "##   File \"<string>\", line 1, in <module>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le produit matriciel peut également s'obtenir à l'aide de l'opérateur `@` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_3 @ t_4.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le produit d'un vecteur avec une matrice est également possible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(t_1, t_3.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opérateurs logiques\n",
    "\n",
    "Pour effectuer des tests logiques sur les éléments d'un tableau, `NumPy` propose des fonctions, répertoriées dans le Tableau\\ \\@ref(numpy-operateurs-logiques). Le résultat retourné par l'application de ces fonctions est un tableau de booléens.\n",
    "\n",
    "| Code | Description |\n",
    "| ------------: | ----------------------------------------------------: |\n",
    "| `greater()` | Supérieur à  |\n",
    "| `greater_equal()` | Supérieur ou égal à |\n",
    "| `less()` | Inférieur à  |\n",
    "| `less_equal()` | Inférieur ou égal à  |\n",
    "| `equal()` | Égal à  |\n",
    "| `not_equal()` | Différent de |\n",
    "| `logical_and()` | Et logique |\n",
    "| `logical_or()` | Ou logique |\n",
    "| `logical_xor()` | XOR logique |\n",
    "\n",
    "Table: (#tab:numpy-operateurs-logiques) Fonctions logiques\n",
    "\n",
    "Par exemple, pour obtenir les éléments de `t` compris entre 10 et 20 (inclus) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[1, 10, 3, 24], [9, 12, 40, 2], [0, 7, 2, 14]])\n",
    "masque = np.logical_and(t <= 20, t >= 10)\n",
    "print(\"masque : \\n\", masque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## masque : \n",
    "##  [[False  True False False]\n",
    "##  [False  True False False]\n",
    "##  [False False False  True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"les éléments de t compris entre 10 et 20 : \\n\",\n",
    "      t[masque])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## les éléments de t compris entre 10 et 20 : \n",
    "##  [10 12 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques constantes {numpy-constantes}\n",
    "\n",
    "\n",
    "`NumPy` propose quelques constantes, dont certaines sont reportées dans le Tableau\\ \\@ref(tab:constantes-numpy).\n",
    "\n",
    "| Code | Description |\n",
    "| ------------: | ----------------------------------------------------: |\n",
    "| `np.inf` | Infini (on obtient $-\\infty$ en écrivant `-np.inf` ou `np.NINF`) |\n",
    "| `np.nan` | Représentation en tant que nombre à virgule flottante de Not a Number |\n",
    "| `np.e` | Constante d'Euler ($e$) |\n",
    "| `np.euler_gamma` | Constante d'Euler-Mascheroni ($\\gamma$) |\n",
    "| `np.pi` | Nombre Pi ($\\pi$) |\n",
    "\n",
    "Table: (#tab:constantes-numpy) Codes de formatages\n",
    "\n",
    "On peut noter la présence de la valeur `NaN`, qui est une valeur spéciale parmi les nombres à virgule flottante. Le comportement de cette constante est spécial.\n",
    "\n",
    "\n",
    "Quand on additionne, soustrait, multiplie ou divise un nombre par cette valeur `NaN`, on obtient `NaN` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Addition : \", np.nan + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Addition :  nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Soustraction : \", np.nan - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Soustraction :  nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multiplication : \", np.nan + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiplication :  nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AddDivisiontion : \", np.nan / 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AddDivisiontion :  nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions universelles\n",
    "\n",
    "Les fonctions universelles (*ufunc* pour *universal functions*) sont des fonctions qui peuvent être appliquées terme à terme aux éléments d'un tableau. On distingue deux types de fonctions universelles : les fonctions unaires, qui effectuent une opération sur une seule, et les fonctions binaires qui effectuent une opération sur deux opérandes.\n",
    "\n",
    "\n",
    "Parmi les *ufuncs*, on retrouve des opérations arithmétiques (addition, multiplication, puissance, valeur absolue, etc.) et des fonctions mathématiques usuelles (fonctions trigonométriques, exponentielle, logarithme, etc.). Le Tableau\\ \\@ref(tab:ufuncs-unaires) répertorie quelques fonctions universelles unaires, tandis que le Tableau\\ \\@ref(tab:ufuncs-binaires) répertories quelques fonctions universelles binaires.\n",
    "\n",
    "| Code | Description |\n",
    "| ------------: | ----------------------------------------------------: |\n",
    "| `negative(x)` | Opposés des éléments de `x` |\n",
    "| `absolute(x)` | Valeurs absolues des éléments de `x` |\n",
    "| `sign(x)` | Signes des éléments de `x` (0, 1 ou -1) |\n",
    "| `rint(x)` | Arrondi de `x` à l'entier |\n",
    "| `floor(x)` | Troncature de `x` à l'entier inférieur |\n",
    "| `ceil(x)` | Troncature de `x` à l'entier supérieur |\n",
    "| `sqrt(x)` | Racine carrée de `x` |\n",
    "| `square(x)` | Carré de `x` |\n",
    "| `sin(x)`, `cos(x)`, `tan(x)` | Sinus (cosinus, et tangente) de `x` |\n",
    "| `sinh(x)`, `cosh(x)`, `tanh(x)` | Sinus (cosinus, et tangente) hyperbolique de `x`  |\n",
    "| `arcsin(x)`, `arccos(x)`, `arctan(x)` | Arc-sinus (arc-cosinus, et arc-tangente) de ``x |\n",
    "| `arcsinh(x)`, `arccosh(x)`, `arctanh(x)` | Arc-sinus (arc-cosinus, et arc-tangente) hyperbolique de ``x |\n",
    "| `hypoth(x,y)` | Hypoténuse $\\sqrt{x^2+y^2}$ |\n",
    "| `degrees(x)` | Conversion des angles `x` de radians en degrés |\n",
    "| `radians(x)` | Conversion des angles `x` de degrés en radians |\n",
    "| `exp(x)` | Exponentielle de `x` |\n",
    "| `expm1(x)` | $e^x-1$ |\n",
    "| `log(x)` | Logarithme népérien des éléments de `x` |\n",
    "| `log10(x)` | Logatithme des éléments de `x` en base 10 |\n",
    "| `log2(x)` | Logarithme des éléments de `x` en base 2 |\n",
    "| `log1p(x)` | $ln(1+x$ |\n",
    "| `exp2(x)` | $2^x$ |\n",
    "| `isnan(x)` | Tableau de booléens indiquant `True` pour les éléments `NaN` |\n",
    "| `isfinite(x)` | Tableau de booléens indiquant `True` pour les éléments non infinis et non-NaN |\n",
    "| `isinf(x)` | Tableau de booléens indiquant `True` pour les éléments infinis |\n",
    "\n",
    "\n",
    "Table: (#tab:ufuncs-unaires) Fonctions universelles unaires\n",
    "\n",
    "\n",
    "| Code | Description |\n",
    "| ------------: | ----------------------------------------------------: |\n",
    "| `add(x,y)` | Addition terme à terme de `x` et `y` |\n",
    "| `subtract(x,y)` | Soustraction terme à terme de `x` et `y` |\n",
    "| `multiply(x,y)` | Multiplication terme à terme de `x` et `y` |\n",
    "| `divide(x,y)` | Division terme à terme de `x` et `y` |\n",
    "| `floor_divide(x,y)` | Quotients entiers des divisions terme à terme de `x` et `y`|\n",
    "| `power(x,y)` | Élévation des éléments de `x` à la puissance des éléments de `y` |\n",
    "| `mod(x,y)` | Restes des divisions eucliennes des éléments de `x` par ceux de `y` |\n",
    "| `round(x,n)` | Arrondi de `x` à $n$ décimales |\n",
    "| `arctan2(x,y)` | Angles polaires de `x` et `y` |\n",
    "\n",
    "Table: (#tab:ufuncs-binaires) Fonctions universelles binaires\n",
    "\n",
    "\n",
    "Pour utiliser ses fonctions, procéder comme dans l'exemple suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "t_2 = np.array([[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]])\n",
    "np.log(t_1) # Logarithme népérien\n",
    "np.subtract(t_1, t_2) # Soustraction des éléments de t_1 par ceux de t_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodes et fonctions mathématiques et statistiques\n",
    "\n",
    "`NumPy` fournit de nombreuses méthodes pour calculer des statistiques sur l'ensemble des valeurs des tableaux, ou sur un des axes des tableaux (par exemple sur l'équivalent de lignes ou des colonnes dans les tableaux à deux dimensions). Certaines sont reportées dans le Tableau\\ \\@ref(tab:numpy-maths-methodes).\n",
    "\n",
    "\n",
    "\n",
    "| Code | Description |\n",
    "| ------------: | ----------------------------------------------------: |\n",
    "| `sum()` | Retourne la somme des éléments |\n",
    "| `prod()` | Retourne le produit des éléments |\n",
    "| `cumsum()` | Retourne la somme cumulée des éléments |\n",
    "| `cumprod()` | Retourne le produit cumulé des éléments |\n",
    "| `mean()` | Retourne la moyenne |\n",
    "| `var()` | Retourne la variance |\n",
    "| `std()` | Retourne l'écart-type |\n",
    "| `min()` | Retourne la valeur minimale |\n",
    "| `max()` | Retourne la valeur maximale |\n",
    "| `argmin()` | Retourne l'indice du premier élément à la plus petite valeur |\n",
    "| `argmax()` | Retourne l'indice du premier élément à la plus grande valeur |\n",
    "\n",
    "Table: (#tab:numpy-maths-methodes) Méthodes mathématiques et statistiques\n",
    "\n",
    "\n",
    "Donnons un exemple de l'utilisation de ces méthodes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = np.array([[1, 2, 3, 4], [-1, 6, 7, 8], [9, -1, 11, 12]])\n",
    "print(\"t_1 : \\n\", t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 : \n",
    "##  [[ 1  2  3  4]\n",
    "##  [-1  6  7  8]\n",
    "##  [ 9 -1 11 12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Somme des éléments : \", t_1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Somme des éléments :  61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Covariance des éléments : \", t_1.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Covariance des éléments :  18.07638888888889"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour appliquer ces fonctions sur un axe donné, on modifie la valeur du paramètre ` axis` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Somme par colonne: \", t_1.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Somme par colonne:  [ 9  7 21 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Somme par ligne: \", t_1.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Somme par ligne:  [10 20 31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumPy` offre aussi certaines fonctions spécifiques aux statistiques, dont certaines sont répertoriées dans le Tableau\\ \\@ref(tab:numpy-stats-fonctions).\n",
    "\n",
    "| Code | Description |\n",
    "| ---------------: | ----------------------------------------------------: |\n",
    "| `sum(x)`, `nansum(x)` | Somme de `x` (`nansum(x)` ne tient pas compte des valeurs `NaN`) |\n",
    "| `mean(x)`, `nanmean()` | Moyenne de `x` |\n",
    "| `median(x)`, `nanmedian()` | Médiane de `x` |\n",
    "| `average(x)` | Moyenne de `x` (possibilité d'utiliser des poids à l'aide du paramètre `weight`) |\n",
    "| `min(x)`, `nanmin()` | Minimum de `x` |\n",
    "| `max(x)`, `nanmax()` | Maximum de `x` |\n",
    "| `percentile(x,p)`, `nanpercentile(n,p)` | P-ème percentile de `x` |\n",
    "| `var(x)`, `nanvar(x)` | Variance de `x` |\n",
    "| `std(x)`, `nanstd()` | Écart-type de `x` |\n",
    "| `cov(x)` | Covariance de `x` |\n",
    "| `corrcoef(x)` | Coefficients de corrélation |\n",
    "\n",
    "Table: (#tab:numpy-stats-fonctions) Fonctions statistiques\n",
    "\n",
    "Pour utiliser les fonctions statistiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = np.array([[1, 2, 3, 4], [-1, 6, 7, 8], [9, -1, 11, 12]])\n",
    "print(\"t_1 : \\n\", t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t_1 : \n",
    "##  [[ 1  2  3  4]\n",
    "##  [-1  6  7  8]\n",
    "##  [ 9 -1 11 12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance: \", np.var(t_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variance:  18.07638888888889"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le tableau comporte des valeurs `NaN`, pour calculer la somme par exempe, si on utilise `sum()`, le résultat sera `NaN`. Pour ignorer les valeurs `NaN`, on utilise une fonction spécifique (ici, `nansum()`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = np.array([[1, 2, np.NaN, 4], [-1, 6, 7, 8], [9, -1, 11, 12]])\n",
    "print(\"somme : \", np.sum(t_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## somme :  nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"somme en ignorant les NaN : \", np.nansum(t_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## somme en ignorant les NaN :  58.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer une moyenne pondérée (prenons un vecteur) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_1 = np.array([1, 1, 4, 2])\n",
    "w = np.array([1, 1, .5, 1])\n",
    "print(\"Moyenne pondérée : \", np.average(v_1, weights=w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moyenne pondérée :  1.7142857142857142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de nombres pseudo-aléatoires\n",
    "\n",
    "\n",
    "La génération de nombres pseudo-aléatoires est permise par le module `random` de `Numpy`. Le lecteur intéressé par les aspects plus statistiques pourra trouver davantage de notions abordées dans le sous-module `stats` de `SciPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Tableau\\ \\@ref(tab:numpy-pseudo-aleatoires) répertorie quelques fonctions permettant de tirer de manière pseudo-aléatoire des nombres avec le module `random` de `Numpy` (en évaluant `??random`, on obtient une liste exhaustive).\n",
    "\n",
    "\n",
    "| Code | Description |\n",
    "| ------------: | ----------------------------------------------------: |\n",
    "| `rand(size)` | Tirage de `size` valeurs selon une Uniforme $[0,1]$ |\n",
    "| `uniform(a,b,size)` | Tirage de `size` valeurs selon une Uniforme $[a ; b]$ |\n",
    "| `randint(a,b,size)` | Tirage de `size` valeurs selon une Uniforme $[a ; b[$ |\n",
    "| `randn(size)` | Tirage de `size` valeurs selon une Normale centrée réduite |\n",
    "| `normal(mu, std, size)` | Tirage de `size` valeurs selon une Normale d'espérance `mu` et d'écart-type `std` |\n",
    "| `binomial(size)` | Tirage de `size` valeurs selon une $\\mathcal{B}in(n,p)$  |\n",
    "| `beta(alpha, beta, size)` | Tirage de `size` valeurs selon une loi bêta de paramètres alpha et beta |\n",
    "| `poisson(lambda, size)` | Tirage de `size` valeurs selon une loi de Poisson de paramètre lambda |\n",
    "| `f(size)` | Tirage de `size` valeurs selon une |\n",
    "| `standard_t(df, size)` | Tirage de `size` valeurs selon une loi de Student à `df` degrés de liberté |\n",
    "\n",
    "\n",
    "Table: (#tab:numpy-pseudo-aleatoires) Quelques fonctions de génération de nombres pseudo-aléatoires\n",
    "\n",
    "\n",
    "Voici un exemple de génération de nombres pseudo aléatoires selon une distribution Gaussienne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [ 0.17829408 -0.21763412  0.17442365  0.34213148  0.87857196  0.6505711\n",
    "##  -0.21430156  0.62979871 -1.68140073  1.73371405]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut générer un tableau à plusieurs dimensions. Par exemple, un tableau à deux dimensions, dans lequel la première dimension contient 10 éléments, contenant chacun 4 tirages aléatoires selon une $\\mathcal{N}(0,1)$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [[-0.54174921 -0.04748063  0.53051893  0.18748516]\n",
    "##  [-0.05221076  0.50723686 -0.18340768  1.2204466 ]\n",
    "##  [ 1.10208709  0.14218753 -0.53491523  2.23497303]\n",
    "##  [-0.12120334  0.3126148  -0.84962088  1.96682462]\n",
    "##  [ 1.38963091 -0.36872079 -0.21167973 -0.30396998]\n",
    "##  [-0.25034757 -0.85750103  1.39865852  1.02237202]\n",
    "##  [ 0.19528422 -0.57441387  0.67004501 -2.89735275]\n",
    "##  [ 0.75609816 -0.77209713 -0.17980928  0.33324138]\n",
    "##  [ 1.3728439   1.25022637 -0.93213787 -0.30889486]\n",
    "##  [-0.88703165 -0.09420696  0.54368064 -2.55861324]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La génération des nombres s'effectue en fonction d'une graine (*seed*), c'est-à-dire un nombre initiant le générateur de nombres pseudo aléatoires. Il est possible de fixer cette graine, pour pouvoir avoir des résultats reproductibles par exemple. Pour ce faire, on peut faire appel à la méthode `seed()`, à qui on indique une valeur en paramètre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "x = np.random.normal(size=10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [ 0.47143516 -1.19097569  1.43270697 -0.3126519  -0.72058873  0.88716294\n",
    "##   0.85958841 -0.6365235   0.01569637 -2.24268495]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fixant à nouveau la graîne, on obtiendra exactement le même tirage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "x = np.random.normal(size=10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [ 0.47143516 -1.19097569  1.43270697 -0.3126519  -0.72058873  0.88716294\n",
    "##   0.85958841 -0.6365235   0.01569637 -2.24268495]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter d'affecter l'environnement global par la graine aléatoire, on peut utiliser la méthode `RandomState`du sous-module `random` de `NumPy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "rs = RandomState(123)\n",
    "x = rs.normal(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8.914369396699438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par ailleurs, la fonction `permutation()` du sous-module `random` permet d'effectuer une permutation aléatoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "y = np.random.permutation(x)\n",
    "print(\"x : \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x :  [0 1 2 3 4 5 6 7 8 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y : \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## y :  [9 7 4 3 8 2 6 1 0 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `shuffle()` du sous-module `random` permet quant à elle d'effectuer une permutation aléatoire des éléments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "print(\"x avant permutation : \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x avant permutation :  [0 1 2 3 4 5 6 7 8 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.permutation(x)\n",
    "print(\"x après permutation : \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x après permutation :  [0 1 2 3 4 5 6 7 8 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "\n",
    "\n",
    "\n",
    "*Premier exercice*\n",
    "\n",
    "Considérons le vecteur suivant : $x = \\begin{bmatrix}1 & 2 & 3 & 4 & 5\\end{bmatrix}$\n",
    "\n",
    "  1. Créer ce vecteur à l'aide d'un tableau que l'on appellera `x`.\n",
    "  2. Afficher le type de `x` puis sa longueur.\n",
    "  3. Extraire le premier élément, puis en faire de même avec le dernier.\n",
    "  4. Extraire les trois premiers éléments et les stocker dans un vecteur que l'on nommera `a`.\n",
    "  5. Extraire les 1er, 2e et 5e éléments du vecteur (attention aux positions) ; les stocker dans un vecteur que l'on nommera `b`.\n",
    "  6. Additionner le nombre 10 au vecteur `x`, puis multiplier le résultat par 2.\n",
    "  7. Effectuer l'addition de `a` et `b`, commenter le résultat.\n",
    "  8. Effectuer l'addition suivante : `x+a` ; commenter le résultat, puis regarder le résultat de `a+x`.\n",
    "  9. Multiplier le vecteur par le scalaire `c` que l'on fixera à 2.\n",
    "  10. Effectuer la multiplication de `a` et `b` ; commenter le résultat.\n",
    "  11. Effectier la multiplication suivante : `x*a` ; commenter le résultats.\n",
    "  12. Récupérer les positions des multiples de 2 et les stocker dans un vecteur que l'on nommera `ind`, piuis conserver uniquement les multiples de 2 de `x` dans un vecteur que l'on nommera `mult_2`.\n",
    "  13. Afficher les éléments de `x` qui sont multiples de 3 *et* multiples de 2.\n",
    "  14. Afficher les éléments de `x` qui sont multiples de 3 *ou* multiples de 2.\n",
    "  15. Calculer la somme des éléments de `x`.\n",
    "  16. Remplacer le premier élément de `x` par un 4.\n",
    "  17. Remplacer le premier élément de `x` par la valeur `NaN`, puis calculer la somme des éléments de `x`.\n",
    "  18 Supprimer le vecteur `x`.\n",
    "\n",
    "*Deuxième exercice*\n",
    "\n",
    "  1. Créer la matrice suivante : $A = \\begin{bmatrix} -3 & 5 & 6 \\\\ -1 & 2 & 2 \\\\ 1 & -1 & -1 \\end{bmatrix}$.\n",
    "  2. Afficher la dimension de `A`, son nombre de colonnes, son nombre de lignes et sa longueur.\n",
    "  3. Extraire la seconde colonne de `A`, puis la première ligne.\n",
    "  4.Extraire l'élément en troisième position à la première ligne.\n",
    "  5. Extraire la sous-matrice de dimension $2\\times 2$ du coin inférieur de `A`, c'est-à-dire $\\begin{bmatrix} 2 & 2 \\\\ -1 & -1 \\end{bmatrix}$.\n",
    "  6. Calculer la somme des colonnes puis des lignes de A.\n",
    "  7. Afficher la diagonale de `A`.\n",
    "  8. Rajouter le vecteur $\\begin{bmatrix} 1 & 2 & 3\\end{bmatrix}^\\top$ à droite de la matrice `A` et stocker le résultat dans un objet appelé `B`.\n",
    "  9. Retirer le quatrième vecteur de `B`.\n",
    "  10. Retirer la première et la troisième ligne de `B`.\n",
    "  11. Ajouter le scalaire 10 à `A`.\n",
    "  12. Ajouter le vecteur $\\begin{bmatrix} 1 & 2 & 3\\end{bmatrix}^\\top$ à `A`.\n",
    "  13. Ajouter la matrice identité $I_3$ à `A`.\n",
    "  14. Diviser tous les éléments de la matrice `A` par 2.\n",
    "  15. Multiplier la matrice `A` par le vecteur ligne $\\begin{bmatrix} 1 & 2 & 3\\end{bmatrix}^\\top$.\n",
    "  16. Afficher la transposée de `A`.\n",
    "  17. Effectuer le produit avec transposition $A^\\top A$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- # Manipulation de données avec `pandas` {#pandas} -->\n",
    "\n",
    "<!-- `pandas` est une librairie open-source basée sur `NumPy` fournissant des structures de données facile à manipuler, et des outils d'analyse de données. Le lecteur familier avec les fonctions de base du langage `R` retrouvera de nombreuses fonctionnalités similaires avec `pandas`. -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- Pour avoir accès aux fonctionnalités de `pandas`, il est coutume de charger la librairie en lui accordant l'alias `pd` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- import pandas as pd -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Nous allons également utiliser des fonctions de `numpy` (c.f. Section\\ \\@ref(numpy)). Assurons-nous de charger cette librairie, si ce n'est pas déjà fait : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- import numpy as np -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- ## Structures -->\n",
    "\n",
    "<!-- Nous allons nous pencher sur deux types de structures, les séries (`serie`) et les dataframes (`DataFrame`). -->\n",
    "\n",
    "\n",
    "<!-- ### Séries -->\n",
    "\n",
    "<!-- Les séries sont des tableaux à une dimension de données indexées. -->\n",
    "\n",
    "<!-- #### Création de séries à partir d'un dictionnaire -->\n",
    "\n",
    "<!-- Pour en créer,on peut définir une liste, puis appliquer la fonction `Series` de `pandas` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, 4, -1, np.nan, .5, 1]) -->\n",
    "<!-- print(s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- L'affichage précédent montre que la série `s` créée contient à la fois les données et un index associé. L'attribut `values` permet d'afficher les valeurs qui sont stockées dans un tableau `numpy` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"valeur de s : \", s.values) -->\n",
    "<!-- print(\"type des valeurs de s : \", type(s.values)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- L'indice est quand à lui stocké dans une structure spécifique de `pandas` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"index de s : \", s.index) -->\n",
    "<!-- print(\"type de l'index de s : \", type(s.index)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Il est possible d'attribuer un nom à la série ainsi qu'à l'index : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s.name = \"ma_serie\" -->\n",
    "<!-- s.name = \"nom_index\" -->\n",
    "<!-- print(\"nom de la série : {} , nom de l'index : {}\".format(s.name, s.index.name)) -->\n",
    "<!-- print(\"série s : \\n\", s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Définition de l'index -->\n",
    "\n",
    "<!-- L'index peut être défini par l'utilisateur, au moment de la création de la série : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [\"o\", \"d\", \"i\", \"l\"]) -->\n",
    "<!-- print(s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On peut définir l'indice avec des valeurs numériques également, sans être forcé de respecter un ordre précis : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [4, 40, 2, 3]) -->\n",
    "<!-- print(s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- L'index peut être modifié par la suite, en venant écraser l'attribut `index` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s.index = [\"o\", \"d\", \"i\", \"l\"] -->\n",
    "<!-- print(\"Série s : \\n\", s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Création de séries particulières -->\n",
    "\n",
    "<!-- Il existe une petite astuce pour créer des séries avec une valeur répétée, qui consiste à fournir un scalaire à la fonction `Series` de `NumPy` et un index dont la longueur correspondra au nombre de fois où le scalaire sera répété : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series(5, index = [np.arange(4)]) -->\n",
    "<!-- print(s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- On peut créer une série à partir d'un dictionnaire : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dictionnaire = {\"Roi\": \"Arthur\", -->\n",
    "<!--                 \"Chevalier_pays_galles\": \"Perceval\", -->\n",
    "<!--                 \"Druide\": \"Merlin\"} -->\n",
    "<!-- s = pd.Series(dictionnaire) -->\n",
    "<!-- print(s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Comme on le note dans la sortie précédente, les clés du dictionnaire ont été utilisées pour l'index. Lors de la création de la série, on peut préciser au paramètre clé des valeurs spécifiques : cela aura pour conséquence de ne récupérer que les observations correspondant à ces clés : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dictionnaire = {\"Roi\": \"Arthur\", -->\n",
    "<!--                 \"Chevalier_pays_galles\": \"Perceval\", -->\n",
    "<!--                 \"Druide\": \"Merlin\"} -->\n",
    "<!-- s = pd.Series(dictionnaire, index = [\"Roi\", \"Druide\"]) -->\n",
    "<!-- print(s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ### Dataframes -->\n",
    "\n",
    "\n",
    "<!-- Les Dataframes correspondent au format de données que l'on rencontre classiquement en économie, des tableaux à deux dimensions, avec des variables en colonnes et des observations en ligne. Les colonnes et lignes des dataframes sont indexées. -->\n",
    "\n",
    "<!-- #### Création de dataframes à partir d'un dictionnaire -->\n",
    "\n",
    "<!-- Pour créer un dataframe, on peut fournir à la fonction `DataFrame()` de `pandas` un dictionnaire pouvant être transformé en `serie`. C'est le cas d'un dictionnaire dont les valeurs associées aux clés ont toutes la même longueur : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"height\" : -->\n",
    "<!--                [58, 59, 60, 61, 62, -->\n",
    "<!--                 63, 64, 65, 66, 67, -->\n",
    "<!--                 68, 69, 70, 71, 72], -->\n",
    "<!--         \"weight\": -->\n",
    "<!--                [115, 117, 120, 123, 126, -->\n",
    "<!--                 129, 132, 135, 139, 142, -->\n",
    "<!--                 146, 150, 154, 159, 164] -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- La position des éléments dans le dataframe sert d'index. Comme pour les séries, les valeur sont accessibles dans l'attribut `values` et l'index dans l'attribut `index`. Les colonnes sont également indexées : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.columns) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- La méthode `head()` permet d'afficher les premières lignes (les 5 premières, par défaut). On peut modifier son paramètre `n` pour indiquer le nombre de lignes à retourner : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.head(2) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Lors de la création d'un dataframe à partir d'un dictionnaire, si on précise le nom des colonnes à importer par une liste de chaînes de caractères fournie au paramètree `columns` de la fonction `DataFrame`, on peut non seulement définir les colonnes à remplir mais également leur ordre d'apparition. -->\n",
    "\n",
    "<!-- Par exemple, pour n'importer que la colonne `weight` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df = pd.DataFrame(dico, columns = [\"weight\"]) -->\n",
    "<!-- print(df.head(2)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Et pour définir l'ordre dans lequel les colonnes apparaîtront : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df = pd.DataFrame(dico, columns = [\"weight\", \"height\"]) -->\n",
    "<!-- print(df.head(2)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Si on indique un nom de colonne absent parmi les clés du dictionnaires, le dataframe résultant contiendra une colonne portant ce nom mais remplie de valeurs `NaN` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df = pd.DataFrame(dico, columns = [\"weight\", \"height\", \"age\"]) -->\n",
    "<!-- print(df.head(2)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Création de dataframes à partir d'une série -->\n",
    "\n",
    "<!-- Un dataframe peut être créé à partir d'une série : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, 4, -1, np.nan], index = [\"o\", \"d\", \"i\", \"l\"]) -->\n",
    "<!-- s.name = \"nom_variable\" -->\n",
    "<!-- df = pd.DataFrame(s, columns = [\"nom_variable\"]) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Si on n'attribue pas de nom à la série, il suffit de ne pas renseigner le paramètre `columns` de la fonction `DataFrame`. Mais dans ce cas, la colonne n'aura pas de non, juste un index numérique. -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, 4, -1, np.nan], index = [\"o\", \"d\", \"i\", \"l\"]) -->\n",
    "<!-- df = pd.DataFrame(s) -->\n",
    "<!-- print(df) -->\n",
    "<!-- print(df.columns.name) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- #### Création de dataframes à partir d'une liste de dictionnaire -->\n",
    "\n",
    "\n",
    "<!-- Un dataframe peut être créé à partir d'une liste de dictionnaires : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico_1 = { -->\n",
    "<!--     \"Nom\": \"Pendragon\", -->\n",
    "<!--     \"Prenom\": \"Arthur\", -->\n",
    "<!--     \"Role\": \"Roi de Bretagne\" -->\n",
    "<!-- } -->\n",
    "<!-- dico_2 = { -->\n",
    "<!--     \"Nom\": \"de Galles\", -->\n",
    "<!--     \"Prenom\": \"Perceval\", -->\n",
    "<!--     \"Role\": \"Chevalier du Pays de Galles\" -->\n",
    "<!-- } -->\n",
    "\n",
    "<!-- df = pd.DataFrame([dico_1, dico_2]) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Si certaines clés sont absentes dans un ou plusieurs des dictionnaires de la liste, les valeurs correspondantes dans le dataframe seront `NaN` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico_3 = { -->\n",
    "<!--     \"Prenom\": \"Guenièvre\", -->\n",
    "<!--     \"Role\": \"Reine de Bretagne\" -->\n",
    "<!-- } -->\n",
    "<!-- df = pd.DataFrame([dico_1, dico_2, dico_3]) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Création de dataframes à partir d'un dictionnaire de séries -->\n",
    "\n",
    "\n",
    "<!-- On peut aussi créer un dataframe à partir d'un dictionnaire de séries. Pour illustrer la méthode, créons deux dictionnaires : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- # PIB annuel 2017 -->\n",
    "<!-- # En millions de dollars courants -->\n",
    "<!-- dico_gdp_current = { -->\n",
    "<!--     \"France\": 2582501.31, -->\n",
    "<!--     \"USA\": 19390604.00, -->\n",
    "<!--     \"UK\": 2622433.96 -->\n",
    "<!-- } -->\n",
    "<!-- # Indice annuel des prix à la consommation -->\n",
    "<!-- dico_cpi = { -->\n",
    "<!--     \"France\": 0.2, -->\n",
    "<!--     \"UK\": 0.6, -->\n",
    "<!--     \"USA\": 1.3, -->\n",
    "<!--     \"Germany\": 0.5 -->\n",
    "<!-- } -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- À partir de ces deux dictionnaires, créons deux séries correspondantes : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_gdp_current = pd.Series(dico_gdp_current) -->\n",
    "<!-- s_cpi = pd.Series(dico_cpi) -->\n",
    "\n",
    "<!-- print(\"s_gdp_current : \\n\", s_gdp_current) -->\n",
    "<!-- print(\"\\ns_cpi : \\n\", s_cpi) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Puis, créons un dictionnaire de séries : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico_de_series = { -->\n",
    "<!--     \"gdp\": s_gdp_current, -->\n",
    "<!--     \"cpi\": s_cpi -->\n",
    "<!-- } -->\n",
    "<!-- print(dico_de_series) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Enfin, créons notre dataframe : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.DataFrame(dico_de_series) -->\n",
    "<!-- print(s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Remarque -->\n",
    "\n",
    "<!-- Le dictionnaire `dico_gdp_current` ne contient pas de clé `Germany`, contrairement au dictionnaire `dico_cpi`. Lors de la création du dataframe, la valeur du PIB pour l'Allemagne a dont été assignée comme `NaN`. -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Création de dataframes à partir d'un tableau `NumPy` à deux dimensions -->\n",
    "\n",
    "<!-- On peut aussi créer un dataframe à partir d'un tableau `Numpy`. Lors de la création, avec la fonction `DataFrame()` de `NumPy`, il est possible de préciser le nom des colonnes (à défaut, l'indiçage des colonnes sera numérique) : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- liste = [ -->\n",
    "<!--     [1, 2, 3], -->\n",
    "<!--     [11, 22, 33], -->\n",
    "<!--     [111, 222, 333], -->\n",
    "<!--     [1111, 2222, 3333] -->\n",
    "<!-- ] -->\n",
    "<!-- tableau_np = np.array(tableau) -->\n",
    "<!-- print(df = pd.DataFrame(tableau_np, -->\n",
    "<!--                   columns = [\"a\", \"b\", \"c\"])) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- #### Dimensions -->\n",
    "\n",
    "<!-- On accède aux dimensions d'un dataframe avec l'attribut `shape`. -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"shape : \", df.shape) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On peut aussi afficher le nombre de lignes comme suit : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"shape : \", len(df)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Et le nombre de colonnes : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"shape : \", len(df.columns)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Modification de l'index -->\n",
    "\n",
    "<!-- Comme pour les séries, on peut modifier l'index une fois que le dataframe a été créé, en venant écraser les valeurs des attributs `index` et `columns`, pour l'index des lignes et colonnes, respectivement : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.index = [\"o\", \"d\", \"i\", \"l\"] -->\n",
    "<!-- df.columns = [\"aa\", \"bb\", \"cc\"] -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- ## Sélection {#pandas-selection} -->\n",
    "\n",
    "<!-- Dans cette section, nous regardons différentes manières de sélectionner des données dans des séries et dataframes. On note deux manières bien distinctes : -->\n",
    "\n",
    "<!-- - une première basée sur l'utiliation de crochets directement sur l'objet pour lequel on souhaite sélectionner certaines parties ; -->\n",
    "<!-- - seconde s'appuyant sur des indexeurs, accessibles en tant qu'attributs d'objets `NumPy` (`loc`, `at`, `iat`, etc.) -->\n",
    "\n",
    "<!-- La seconde méthode permet d'éviter certaines confusions qui peuvent apparaître dans le cas d'index numériques. -->\n",
    "\n",
    "<!-- ### Pour les séries -->\n",
    "\n",
    "<!-- Dans un premier temps, regardons les manières d'extraire des valeurs contenues dans des séries. -->\n",
    "\n",
    "\n",
    "<!-- #### Avec les crochets -->\n",
    "\n",
    "<!-- On peut utiliser l'index pour extraire les données : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, 4, -1, np.nan, .5, 1]) -->\n",
    "<!-- s[0] # 1er élément de s -->\n",
    "<!-- s[1:3] # du 2e élément (inclus) au 4e (non inclus) -->\n",
    "<!-- s[[0,4]] # 1er et 5e éléments -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On note que contrairement aux tableaux `numpy` ou aux listes, on ne peut pas utiliser des valeurs négatives pour l'index afin de récupérer les données en comptant leur position par rapport à la fin : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s[-2] -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Dans le cas d'un indice composé de chaînes de caractères, il est alors possible, pour extraire les données de la série, de faire référence soit au contenu de l'indice (pour faire simple, son nom), soit à sa position : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [\"o\", \"d\", \"i\", \"l\"]) -->\n",
    "<!-- print(\"La série s : \\n\", s) -->\n",
    "<!-- print('s[\"d\"] : \\n', s[\"d\"]) -->\n",
    "<!-- print('s[1] : \\n', s[1]) -->\n",
    "<!-- print(\"éléments o et i : \\n\", s[[\"o\", \"i\"]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- Par contre, dans le cas où l'indice est défini avec des valeurs numériques, pour extraire les valeurs à l'aide des crochets, ce sera par la valeur de l'indice et pas en s'appuyant sur la position : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [4, 40, 2, 3]) -->\n",
    "<!-- print(s[40]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Avec les indexeurs -->\n",
    "\n",
    "<!-- Pandas propose deux types d'indiçage multi-axes : `loc`, `iloc`.  Le premier est principalement basé sur l'utilisation des labels des axes, tandis que le second s'appuie principalement sur les positions à l'aide d'entiers. -->\n",
    "\n",
    "<!-- Pour les besoins de cette partie, créons deux séries ; une première avec un index textuel, une deuxième avec un index numérique : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [5, 0, 4, 1]) -->\n",
    "<!-- s_texte = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [\"c\", \"a\", \"b\", \"d\"]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- ##### Extraction d'un seul élément -->\n",
    "\n",
    "<!-- Pour extraire un objet avec `loc`, on utilise le nom de l'indice : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(s_num.loc[5], s_texte.loc[\"c\"]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Pour extraire un élément unique avec `iloc`, il suffit d'indiquer sa position : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- (s_num.iloc[1], s_texte.iloc[1]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ##### Extraction de plusieurs éléments -->\n",
    "\n",
    "\n",
    "<!-- Pour extraire plusieurs éléments avec `loc`, on utilise les noms (labels) des indices, que l'on fournit dans une liste : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"éléments aux labels 5 et 4 :\\n\", s_num.loc[[5,4]]) -->\n",
    "<!-- print(\"éléments aux labels c et b : \\n\", s_texte.loc[[\"c\", \"b\"]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Pour extraire plusieurs éléments avec `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"éléments aux positions 0 et 2 :\\n\", s_num.iloc[[0,2]]) -->\n",
    "<!-- print(\"éléments aux positions 0 et 2 : \\n\", s_texte.iloc[[0,2]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ##### Découpage {#decoupage-series} -->\n",
    "\n",
    "\n",
    "<!-- On peut effectuer des découpages de séries, pour récupérer des éléments consécutifs : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"éléments des labels 5 jusqu'à 4 :\\n\", s_num.loc[5:4]) -->\n",
    "<!-- print(\"éléments des labels c à b : \\n\", s_texte.loc[\"c\":\"b\"]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Pour extraire plusieurs éléments avec `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"éléments aux positions de 0 à 2 :\\n\", s_num.iloc[0:2]) -->\n",
    "<!-- print(\"éléments aux positions de 0 à 2 : \\n\", s_texte.iloc[0:2]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Comme ce que l'on a vu jusqu'à présent, la valeur supérieur de la limite n'est pas incluse dans le découpage. -->\n",
    "\n",
    "\n",
    "<!-- ##### Masque -->\n",
    "\n",
    "<!-- On peut aussi utiliser un masque pour extraire des éléments, indifféremment en utilisant `loc` ou `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"\\n\",s_num.loc[[True, False, False, True]]) -->\n",
    "<!-- print(\"\\n\", s_texte.loc[[True, False, False, True]]) -->\n",
    "<!-- print(\"\\n\", s_num.iloc[[True, False, False, True]]) -->\n",
    "<!-- print(\"\\n\", s_texte.iloc[[True, False, False, True]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- ##### Quel est l'intérêt ? -->\n",
    "\n",
    "\n",
    "<!-- Pourquoi introduir de telles manières d'extraire les données et ne pas se contenter de l'extraction à l'aide des crochers sur les objets ? Regardons un exemple simple. Admettons que nous disposons de la série `s_num`, avec un indice composé d'entiers n'étant pas une séquence allant de 0 au nombre d'éléments. Dans ce cas, si nous souhaitons récupérer récupérer le 2e élément, du fait de l'indice composé de valeurs numériques, nous ne pouvons pas l'obtenir en demandant `s[1]`. Pour extraire le 2e de la série, on doit savoir que son indice vaut `0` et ainsi demander : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"L'élément dont l'index vaut 0 : \", s_num[0]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Pour pouvoir effectuer l'extraction en fonction de la position, il est bien pratique d'avoir cet attribut `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"L'élément en 2e position :\", s_num.iloc[1]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- ### Pour les dataframes -->\n",
    "\n",
    "<!-- À présent, regardons différentes manières d'extraire des données depuis un dataframe. Créons deux dataframes en exemple, l'une avec un index numérique ; une autre avec un index textuel : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"height\" : [58, 59, 60, 61, 62], -->\n",
    "<!--         \"weight\": [115, 117, 120, 123, 126], -->\n",
    "<!--         \"age\": [28, 33, 31, 31, 29], -->\n",
    "<!--         \"taille\": [162, 156, 172, 160, 158], -->\n",
    "<!--        } -->\n",
    "<!-- df_num = pd.DataFrame(dico) -->\n",
    "<!-- df_texte = pd.DataFrame(dico, index=[\"a\", \"e\", \"c\", \"b\", \"d\"]) -->\n",
    "<!-- print(\"df_num : \\n\", df_num) -->\n",
    "<!-- print(\"df_texte : \\n\", df_texte) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour faire simple, lorsqu'on veut effectuer une extraction avec les attributs  `iloc`, la syntaxe est la suivante : -->\n",
    "\n",
    "<!-- ```{python, eval=F, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.iloc[selection_lignes, selection_colonnes] -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- avec `selection_lignes` : -->\n",
    "\n",
    "<!-- - une valeur unique : `1` (seconde ligne) ; -->\n",
    "<!-- - une liste de valeurs : `[2, 1, 3]` (3e ligne, 2e ligne et 4e ligne) ; -->\n",
    "<!-- - un découpage : `[2:4]` (de la 3e ligne à la 4e ligne (non incluse)). -->\n",
    "\n",
    "<!-- pour `selection_colonnes` : -->\n",
    "\n",
    "<!-- - une valeur unique : `1` (seconde colonne) ; -->\n",
    "<!-- - une liste de valeurs : `[2, 1, 3]` (3e colonne, 2e colonne et 4e colonne) ; -->\n",
    "<!-- - un découpage : `[2:4]` (de la 3e colonne à la 4e colonne (non incluse)). -->\n",
    "\n",
    "\n",
    "<!-- Avec `loc`, la syntaxe est la suivante : -->\n",
    "\n",
    "\n",
    "<!-- ```{python, eval=F, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.loc[selection_lignes, selection_colonnes] -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- avec `selection_lignes` : -->\n",
    "\n",
    "<!-- - une valeur unique : `\"a\"` (ligne nommée `a`) ; -->\n",
    "<!-- - une liste de noms : `[\"a\", \"c\", \"b\"]` (lignes nommées \"a\", \"c\" et \"b\") ; -->\n",
    "<!-- - un masque : `df.['a']<10` (lignes pour lesquelles les valeurs du masque valent `True`). -->\n",
    "\n",
    "<!-- pour `selection_colonnes` : -->\n",
    "\n",
    "<!-- - une valeur unique : `a` (colonne nommée `a`) ; -->\n",
    "<!-- - une liste de valeurs : `[\"a\", \"c\", \"b\"]` (colonnes nommées \"a\", \"c\" et \"b\") ; -->\n",
    "<!-- - un découpage : `[\"a\":\"c\"]` (de la colonne nommée \"a\" à la colonne nommée \"c\"). -->\n",
    "\n",
    "<!-- #### Extraction d'une ligne -->\n",
    "\n",
    "<!-- Pour extraire une ligne d'un dataframe, on peut utiliser le nom de la ligne avec `loc` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Ligne nommée 'e':\\n\", df_texte.loc[\"e\"]) -->\n",
    "<!-- print(\"\\nLigne nommée 'e':\\n\", df_num.loc[1]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Ou bien, sa position avec `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Ligne en position 0:\\n\", df_texte.iloc[0]) -->\n",
    "<!-- print(\"\\nLigne en position 0:\\n\", df_num.iloc[0]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Extraction de plusieurs lignes -->\n",
    "\n",
    "<!-- Pour extraire plusieurs lignes d'un dataframe, on peut utiliser leur noms avec `loc` (dans un tableau) : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Lignes nommées a et c :\\n\", df_texte.loc[[\"a\", \"c\"]]) -->\n",
    "<!-- print(\"\\nLignes nommées 0 et 2:\\n\", df_num.loc[[0, 2]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Ou bien, leur position avec `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Lignes aux positions 0 et 3:\\n\", df_texte.iloc[[0, 3]]) -->\n",
    "<!-- print(\"\\nLignes aux positions 0 et 3:\\n\", df_num.iloc[[0, 3]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Découpage de plusieurs lignes {#decoupage-df-lignes} -->\n",
    "\n",
    "<!-- On peut récupérer une suite de ligne en délimitant la première et la dernière à extraire en fonction de leur nom et en utilisant `loc` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Lignes du label a à c:\\n\", df_texte.loc[\"a\":\"c\"]) -->\n",
    "<!-- print(\"\\Lignes du label 0 à 2:\\n\", df_num.loc[0:2]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Avec l'attribut `iloc`, c'est également possible (encore une fois, la borne supérieure n'est pas incluse) : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Lignes des positions 0 à 3 (non incluse):\\n\", df_texte.iloc[0:3]) -->\n",
    "<!-- print(\"\\nLignes des positions 0 à 3 (non incluse):\\n\", df_num.iloc[0:3]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Masque {#masque-extraction-ligne} -->\n",
    "\n",
    "<!-- On peut aussi utiliser un masque pour sélectionner certaines lignes. Par exemple, si on souhaite récupérer les lignes pour lesquelles la variable `height` a une valeur supérieure à 60, on utilise le masque suivante : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- masque = df_texte[\"height\"]> 60 -->\n",
    "<!-- print(masque) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Pour filtrer : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df_texte.loc[masque]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Extraction d'une seule colonne -->\n",
    "\n",
    "<!-- Pour extraire une colonne d'un dataframe, on peut utiliser des crochets et faire référence au nom de la colonne (qui est indexée par les noms) : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df_texte['weight'].head(2)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- En ayant sélectionné une seule colonne, on obtient une série (l'index du dataframe est conservé pour la série) : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(type(df_texte['weight'])) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- On peut également extraire une colonne en faisant référence à l'attribut du dataframe portant le nom de cette colonne : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df_texte.weight.head(2)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Comme pour les séries, on peut s'appuyer sur les attributs `loc` et `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Colone 2 (loc):\\n\", df_texte.loc[:,\"weight\"]) -->\n",
    "<!-- print(\"Colonne 2 (iloc):\\n\", df_texte.iloc[:,1]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Extraction de plusieurs colonnes -->\n",
    "\n",
    "\n",
    "<!-- Pour extraire plusieurs colonnes, il suffit de placer les noms des colonnes dans un tableau : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df_texte[[\"weight\", \"height\"]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- L'ordre dans lequel on appelle ces colonnes correspond à l'ordre dans lequel elles seront retournées. -->\n",
    "\n",
    "<!-- À nouveau, on peut utuliser l'attribut `loc` (on utilise les deux points ici pour dire que l'on veut toutes les lignes) : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Colonnes de weight à height:\\n\", df_texte.loc[:,[\"weight\", \"height\"]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Et l'attribut `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Colonnes 2 et 1 :\\n\", df_num.iloc[:,[1,0]]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- #### Découpage de plusieurs colonnes {#decoupage-df-colonnes} -->\n",
    "\n",
    "<!-- Pour effectuer un découpage, on peut utiliser les attributs `loc` et `iloc`. Attention, on ne place pas le nom des colonnes servant pour le découpage dans un tableau ici : -->\n",
    "\n",
    "<!-- Avec `loc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Colones 2 et 2:\\n\", df_texte.loc[:, \"height\":\"age\"]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Et avec l'attribut `iloc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Colonnes de la position 0 à 2 (non incluse) :\\n\", -->\n",
    "<!--       df_texte.iloc[:, 0:2]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Extraction de lignes et colonnes -->\n",
    "\n",
    "<!-- À présent que nous avons passé en revue de nombreuses manières de sélectionner une ou plusieurs lignes ou colonnes, nous pouvons également mentionner qu'il est possible de faire des sélections de colonnes et de lignes dans une même instruction. -->\n",
    "\n",
    "\n",
    "<!-- Par exemple, avec `iloc`, sélectionnons les lignes de la position 0 à la position 2 (non incluse) et les colonnes de la position 1 à 3 (non incluse) : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df_texte.iloc[0:2, 1:3]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Avec `loc`, sélectionnons les lignes nommées `a` et `c` et les colonnes de celle nommée `weight` jusqu'à `age`. -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df_texte.loc[[\"a\", \"c\"], \"weight\":\"age\"] -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ## Renommage des colonnes dans un dataframe -->\n",
    "\n",
    "<!-- Pour renommer une colonne dans un dataframe, `pandas` propose la méthode `rename()`. Prenons un exemple avec notre dataframe `df` : -->\n",
    "\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"height\" : [58, 59, 60, 61, 62], -->\n",
    "<!--         \"weight\": [115, 117, 120, 123, 126], -->\n",
    "<!--         \"age\": [28, 33, 31, 31, 29], -->\n",
    "<!--         \"taille\": [162, 156, 172, 160, 158], -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Renommons la colonne `height` en `taille`, à l'aide d'un dicionnaire précisé au paramètre `columns`, avec comme clé le nom actuel de la colonne, et en valeur le nouveau nom : -->\n",
    "\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.rename(index=str, columns={\"height\": \"taille\"}, inplace=True) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Pour que le changement soit effectif, on indique `inplace=True`, sinon, la modification n'est pas apportée au dataframe. -->\n",
    "\n",
    "<!-- Pour renommer plusieurs colonnes en même temps, il suffit de fournir plusieurs couples de clés valeurs dans le dictionnaire : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.rename(index=str, -->\n",
    "<!--           columns={\"weight\": \"masse\", \"age\" : \"annees\"}, -->\n",
    "<!--           inplace=True) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- ## Filtrage -->\n",
    "\n",
    "\n",
    "<!-- Pour effectuer une filtration des données dans un tableau, en fonction des valeurs rencontrées pour certaines variables, on utilise des masques, comme indiqué dans la Section\\ \\@ref(masque-extraction-ligne). -->\n",
    "\n",
    "\n",
    "<!-- Redennons quelques exemples ici, en redéfinissant notre dataframe : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"height\" : [58, 59, 60, 61, 62], -->\n",
    "<!--         \"weight\": [115, 117, 120, 123, 126], -->\n",
    "<!--         \"age\": [28, 33, 31, 31, 29], -->\n",
    "<!--         \"taille\": [162, 156, 172, 160, 158], -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- L'idée consiste à créer un masque retournant une série contenant des valeurs booléennes, une par ligne. Lorsque la valeur de la ligne du masque vaut `True`, la ligne du dataframe sur lequel sera appliqué le masque sera retenue, tandis qu'elle ne le sera pas quand la valeur de la ligne du masque vaut `False`. -->\n",
    "\n",
    "\n",
    "<!-- Regardons un exemple simple, dans lequel nous souhaitons conserver les observations uniquement pour lesquelles la valeur de la variable `age` est inférieure à 30 : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- masque = df[\"age\"] < 30 -->\n",
    "<!-- print(masque) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Il reste alors à appliquer ce masque, avec `loc`. On souhaite l'ensemble des colonnes, mais seulement quelques lignes : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.loc[masque]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Note : cela fonctionne aussi sans `loc` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df[masque]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Plus simplement, on peut utiliser la méthode `query()` de `pandas`. On fournit une expression booléenne à évaluer à cette méthode pour filtrer les données : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.query(age<30)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- La requête peut être un peu plus complexe, en combinant opérateurs de comparaison (c.f. Section\\ \\@ref(operateurs-comparaison)) et opérateurs logiques (c.f. Section\\ \\@ref(operateurs-logiques)). Par exemple, admettons que nous voulons filtrer les valeurs du dataframe pour ne retenir que les observations pour lesquelles la taille est inférieure ou égale à 62 et la masse strictement supérieure à 120. La requête serait alors : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.query(\"weight > 120 and height < 62\")) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On peut noter que l'instruction suivante donne le même résultat : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.query(\"weight > 120\").query(\"height < 62\")) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ### Test d'appartenance -->\n",
    "\n",
    "<!-- Pour créer un masque indiquant si les valeurs d'une série ou d'un dataframe appartiennent à un ensemble, on peut utiliser la méthode `isin()`. Par exemple, retournons un masque indiquant si les valeurs de la colonne `height` de `df` sont dans l'intervalle $[59,60]$ : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.height.isin(np.arange(59,61)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- ## Valeurs manquantes -->\n",
    "\n",
    "<!-- En économie, il est assez fréquent de récupérer des données incomplètes. La manière dont les données manquantes sont gérées par `pandas` est le recours aux deux valeurs spéciales : `None` et `NaN`. -->\n",
    "\n",
    "<!-- La valeur `None` peut être utilisée dans les tableaux `NumPy` uniquement quand le type de ces derniers est `object`. -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- tableau_none = np.array([1, 4, -1, None]) -->\n",
    "<!-- print(tableau_none) -->\n",
    "<!-- print(type(tableau_none)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Avec un tableau de type `object`, les opérations effectuées sur les données seront moins efficaces qu'avec un tableau d'un type numérique [@vanderplas2016python, p 121]. -->\n",
    "\n",
    "<!-- La valeur `NaN` est une valeur de nombre à virgule flottante (c.f. Section\\ \\@ref(numpy-constantes)). `NumPy` la gère différemment de `NaN`, et n'assigne passe type `object` d'emblée en présence de `NaN` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- tableau_nan = np.array([1, 4, -1, np.nan]) -->\n",
    "<!-- print(tableau_nan) -->\n",
    "<!-- print(type(tableau_nan)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Avec `pandas`, ces deux valeurs, `None` et `NaN` peuvent être présentes : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([1, None, -1, np.nan]) -->\n",
    "<!-- print(s) -->\n",
    "<!-- print(type(s)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Cela tient aussi pour les tableaux : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"height\" : [58, 59, 60, 61, np.nan], -->\n",
    "<!--         \"weight\": [115, 117, 120, 123, 126], -->\n",
    "<!--         \"age\": [28, 33, 31, np.nan, 29], -->\n",
    "<!--         \"taille\": [162, 156, 172, 160, 158], -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On note toutefois que seule le type des variables pour lesquelles existent des valeurs manquantes sont passées en `float64` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.dtypes) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- Remarque -->\n",
    "\n",
    "<!-- On note que les données sont enregistrées sur un type `float64`. Lorsqu'on travaille sur un tableau ne comportant pas de valeurs manquantes, dont le type est `int` ou `bool`, si on introduit une valeur manquante, `pandas` changera le type des données en `float64` et `object`, respectivement. -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- `pandas` propose différentes pour manipuler les valeurs manquantes. -->\n",
    "\n",
    "\n",
    "<!-- ### Repérer les valeurs manquantes -->\n",
    "\n",
    "<!-- Avec la méthode `isnull()`, un masque de booléens est retournée, indiquant `True` pour les observations dont la valeur est `NaN` ou `None` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(s.isnull()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour savoir si une valeur n'est pas nulle, on dispose de la méthode `notnull()` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(s.notnull()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ### Retirer les observations avec valeurs manquantes -->\n",
    "\n",
    "<!-- La méthode `dropna()` permet quant à elle de retirer les observations disposant de valeurs nulles : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.dropna()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- ### Retirer les valeurs manquantes par d'autres valeurs -->\n",
    "\n",
    "<!-- Pour remplacer les valeurs manquantes par d'autres valeurs, `pandas` propose d'utiliser la méthode `fillna()` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.fillna(-9999)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- ## Suppressions -->\n",
    "\n",
    "<!-- Pour supprimer une valeur sur un des axes d'une série ou d'un dataframe, `NumPy` propose la méthode `drop()`. -->\n",
    "\n",
    "\n",
    "<!-- ### Suppression d'éléments dans une série -->\n",
    "\n",
    "<!-- Pour illustrer le fonctionnement de la méthode `drop()`, créons une série avec un index numérique, une autre avec un index textuel : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [5, 0, 4, 1]) -->\n",
    "<!-- s_texte = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [\"c\", \"a\", \"b\", \"d\"]) -->\n",
    "\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On peut supprimer un élément d'une série en utilisant son nom : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"pour s_num : \\n\", s_num.drop(5)) -->\n",
    "<!-- print(\"\\npour s_texte : \\n\", s_texte.drop(\"c\")) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On peut aussi aller récupérer le nom en fonction de la position, en passant par un détour en utilisant la méthode `index()` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- pritn(s.drop(s_num.index[0])) -->\n",
    "<!-- print(\"s_num.index[0] : \", s_num.index[0]) -->\n",
    "<!-- print(\"s_texte.index[0] : \", s_texte.index[0]) -->\n",
    "\n",
    "<!-- print(\"pour s_num : \\n\", s_num.drop(s_num.index[0])) -->\n",
    "<!-- print(\"\\npour s_texte : \\n\", s_texte.drop(s_texte.index[0])) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- Pour supprimer plusieurs éléments, il suffit de fournir plusieurs noms d'indice dans une liste à la méthode `drop()` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"pour s_num : \\n\", s_num.drop([5, 4])) -->\n",
    "<!-- print(\"\\npour s_texte : \\n\", s_texte.drop([\"c\", \"b\"])) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- À nouveau, on peut aller récupérer le nom en fonction de la position, en passant par un détour en utilisant la méthode `index()` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- pritn(s.drop(s_num.index[0])) -->\n",
    "<!-- print(\"s_num.index[[0,2]] : \", s_num.index[[0,2]]) -->\n",
    "<!-- print(\"s_texte.index[[0,2]] : \", s_texte.index[[0,2]]) -->\n",
    "\n",
    "<!-- print(\"pour s_num : \\n\", s_num.drop(s_num.index[[0,2]])) -->\n",
    "<!-- print(\"\\npour s_texte : \\n\", s_texte.drop(s_texte.index[[0,2]])) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- Il est possible d'utiliser un découpage également pour obtenir la série sans le ou les éléments (c.f. Section\\ \\@ref(decoupage-series)) -->\n",
    "\n",
    "\n",
    "<!-- ### Suppression d'éléments dans un dataframe -->\n",
    "\n",
    "\n",
    "<!-- Pour illustrer le fonctionnement de la méthode `drop()` sur un dataframe, créons-en un : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [5, 0, 4, 1]) -->\n",
    "<!-- s_texte = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [\"c\", \"a\", \"b\", \"d\"]) -->\n",
    "<!-- dico = {\"height\" : [58, 59, 60, 61, np.nan], -->\n",
    "<!--         \"weight\": [115, 117, 120, 123, 126], -->\n",
    "<!--         \"age\": [28, 33, 31, np.nan, 29], -->\n",
    "<!--         \"taille\": [162, 156, 172, 160, 158], -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- #### Suppressions de lignes -->\n",
    "\n",
    "<!-- Pour supprimer une ligne d'un dataframe, on peut faire référence à son nom (ici, les noms sont des numéros, mais ce sont bien des labels) : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Supprimer la première ligne :  \\n\", df.drop(0)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Si les lignes ont des labels textuels, on peut au préalable aller les récupérer à l'aide de la méthode `index()` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- label_pos_0 = df.index[0] -->\n",
    "<!-- print(\"Supprimer la première ligne :  \\n\", df.drop(label_pos_0)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour supprimer plusieurs lignes, on donne le nom de ces lignes dans une liste à la méthode `drop()` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Supprimer les 1ère et 4e lignes :  \\n\", df.drop([0,3])) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Ou encore, en indiquant les positions des lignes : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- label_pos = df.index[[0, 3]] -->\n",
    "<!-- print(\"Supprimer les 1ère et 4e lignes :  \\n\", df.drop(label_pos)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Il est possible d'utiliser un découpage également pour obtenir la série sans le ou les éléments (c.f. Sections\\ \\@ref(decoupage-df-lignes) et \\@ref(decoupage-df-colonnes)) -->\n",
    "\n",
    "\n",
    "<!-- #### Suppressions de colonnes -->\n",
    "\n",
    "\n",
    "<!-- Pour supprimer une colonne d'un dataframe, on procède de la même manière que pour les lignes, mais en ajoutant le paramètre `axis=1` à la méthode `drop()` pour préciser que l'on s'intéresse aux colonnes : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Supprimer la première colonne :  \\n\", df.drop(\"height\", axis=1)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On peut au préalable aller récupérer les labels des colonnes en fonction de leur position à l'aide de la méthode `columns()` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- label_pos = df.columns[0] -->\n",
    "<!-- print(\"label_pos : \", label_pos) -->\n",
    "<!-- print(\"Supprimer la première colonne :  \\n\", df.drop(label_pos, axis=1)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour supprimer plusieurs colonnes, on donne le nom de ces colonnes dans une liste à la méthode `drop()` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"Supprimer les 1ère et 4e colonnes :  \\n\", df.drop([\"height\", \"taille\"], axis = 1)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Ou encore, en indiquant les positions des colonnes : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- label_pos = df.columns[[0, 3]] -->\n",
    "<!-- print(\"Supprimer les 1ère et 4e colonnes :  \\n\", df.drop(label_pos, axis=1)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Il est possible d'utiliser un découpage également pour obtenir la série sans le ou les éléments (c.f. Sections\\ \\@ref(decoupage-df-lignes) et \\@ref(decoupage-df-colonnes)) -->\n",
    "\n",
    "\n",
    "<!-- ## Remplacement de valeurs -->\n",
    "\n",
    "<!-- Nous allons à présent regarder comment modifier une ou plusieurs valeurs, dans le cas d'une série puis d'un dataframe. -->\n",
    "\n",
    "<!-- ### Pour une série -->\n",
    "\n",
    "<!-- Pour modifier une valeur particulière dans une série ou dans un dataframe, on peut utiliser le symbole égale (`=`) en ayant au préalable ciblé l'emplacement de la valeur à modifier, à l'aide des techniques d'extraction expliquées dans la Section\\ \\@ref(pandas-selection). -->\n",
    "\n",
    "<!-- Par exemple, considérons la série suivante : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [5, 0, 4, 1]) -->\n",
    "<!-- print(\"s_num : \", s_num) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Modifions le deuxième élément élément de `s_num`, pour lui donner la valeur -3 : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num.iloc[1] = -3 -->\n",
    "<!-- print(\"s_num : \", s_num) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Il est évidemment possible de modifier plusieurs valeurs à la fois. -->\n",
    "\n",
    "<!-- Il suffit à nouveau de cibler les positions (on peu utiliser de nombreuses manières de le faire) et de fournir un objet de dimensions équivalentes pour venir remplacer les valeurs ciblées. Par exemple, dans notre série `s_num`, allons remplacer les valeurs en position 1 et 3 (2e et 4e valeurs) par -10 et -9 : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num.iloc[[1,3]] = [-10, -9] -->\n",
    "<!-- print(s_num) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ### Pour un dataframe -->\n",
    "\n",
    "<!-- Considérons le dataframe suivant : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"ville\" : [\"Marseille\", \"Aix\", -->\n",
    "<!--                    \"Marseille\", \"Aix\", \"Paris\", \"Paris\"], -->\n",
    "<!--         \"annee\": [2019, 2019, 2018, 2018,2019, 2019], -->\n",
    "<!--         \"x\": [1, 2, 2, 2, 0, 0], -->\n",
    "<!--         \"y\": [3, 3, 2, 1, 4, 4], -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Modifications d'une valeur particulière -->\n",
    "\n",
    "<!-- Modifions la valeur de la première ligne de `df` pour la colonne `annee`, pour que celle-ci vaille 2020. Dans un premier temps, récupérons la position de la colonne `annee` dans le dataframe, à l'aide de la méthode `get_loc()` appliquée à l'attribut `colnames` du dataframe : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- pos_annee = df.columns.get_loc(\"annee\") -->\n",
    "<!-- print(\"pos_annee : \", pos_annee) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Ensuite, effectuons la modification : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.iloc[0,pos_annee] = 2020 -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Modifications sur une ou plusieurs colonnes -->\n",
    "\n",
    "<!-- Pour modifier toutes les valeurs d'une colonne pour y placer une valeur particulière, par exemple un 2 dans la colonne `x` de `df` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.x = 2 -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- On peut également modifier les valeurs de la colonne en fournissant une liste de valeurs : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.x = [2, 3, 4, 2, 1, 0] -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On peut donc  imaginer modifier les valeurs d'une colonne en fonction des valeurs que l'on lit dans une autre colonne. Par exemple, admettons le code suivant : si la valeur de `y` vaut 2, alors celle de x vaut \"a\", si la valeur de `y` vaut 1, lors celle de `x` vaut \"b\", sinon, elle vaut `NaN`. Dans un premier temps, construisons une liste contenant les valeurs à insérer (que nous nommerons `nv_val`), à l'aide d'une boucle. Nous allons parcourir tous les éléments de la colonne `y`, et à chaque itération ajouter à `nv_val` la valeur obtenue en effectuant nos comparaisons : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- nv_val = [] -->\n",
    "<!-- for i in np.arange(len(df.index)): -->\n",
    "<!--         if df.y[i] == 2: -->\n",
    "<!--             nv_val.append(\"a\") -->\n",
    "<!--         elif df.y[i] == 1: -->\n",
    "<!--             nv_val.append(\"b\") -->\n",
    "<!--         else: -->\n",
    "<!--             nv_val.append(np.nan) -->\n",
    "<!-- print(\"nv_val : \", nv_val) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Nous sommes prêts à modifier le contenu de la colonne `x` de `df` pour le remplacer par `nv_val` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.x = nv_val -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour remplacer plusieurs colonnes en même temps : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df[[\"x\", \"y\"]] = [[2, 3, 4, 2, 1, 0], 1] -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Dans l'instruction précédente, nous avons remplacé le contenu des colonnes `x` et `y` par une vecteur de valeurs écrites à la main pour `x` et par la valeur 1 pour toutes les observations pour `y`. -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Modifications sur une ou plusieurs lignes -->\n",
    "\n",
    "\n",
    "<!-- Pour remplacer une ligne par une valeur constante (peu d'intérêt ici) : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.iloc[1,:] = 1 -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Il peut être plus intéressant de remplacer une observation comme suit : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.iloc[1,:] = [\"Aix\", 2018, 1, 2, 3] -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour remplacer plusieurs lignes, la méthode est identique : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.iloc[[1,3],:] = [ -->\n",
    "<!--     [\"Aix\", 2018, 1, 2, 3], -->\n",
    "<!--     [\"Aix\", 2018, -1, -1, -1] -->\n",
    "<!-- ] -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ## Ajout de valeurs {#pandas-ajout-valeurs} -->\n",
    "\n",
    "<!-- Regardons à présent comment ajouter des valeurs, dans une série d'abord, puis dans un dataframe. -->\n",
    "\n",
    "<!-- ### Pour une série -->\n",
    "\n",
    "<!-- Considérons la série suivante : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num = pd.Series([1, 4, -1, np.nan], -->\n",
    "<!--              index = [5, 0, 4, 1]) -->\n",
    "<!-- print(\"s_num : \", s_num) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- #### Ajout d'une seule valeur dans une série -->\n",
    "\n",
    "\n",
    "<!-- Pour ajouter une valeur, on utlise la méthode `append()`. Ici, avec `s_num`, comme l'index est manuel, nous sommes obligé de fournir une série avec une valeur pour l'index également : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num_2 = pd.Series([1], index = [2]) -->\n",
    "<!-- print(\"s_num_2 : \\n\", s_num_2) -->\n",
    "<!-- s_num = s_num.append(s_num_2) -->\n",
    "<!-- print(\"s_num : \\n\", s_num) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On note que la méthode `append()` retourne une vue, et que pour répercuter l'ajout, il est nécessaire d'effectuer une nouvelle assignation. -->\n",
    "\n",
    "\n",
    "<!-- En ayant une série avec un index numérique généré automatiquement, on peut préciser la valeur `True` pour le paramètre `ignore_index` de la méthode `append()` pour indiquer de ne pas tenir compte de la valeur de l'index de l'objet que l'on ajoute : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([10, 2, 4]) -->\n",
    "<!-- s = s.append(pd.Series([2]), ignore_index=True) -->\n",
    "<!-- print(\"s : \\n\", s) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- #### Ajout de plusieurs valeurs dans une série -->\n",
    "\n",
    "<!-- Pour ajouter plusieurs valeurs, on utlise la méthode `append()`. Ici, avec `s_num`, comme l'index est manuel, nous sommes obligé de fournir une série avec une valeur pour l'index également : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s_num_2 = pd.Series([1], index = [2]) -->\n",
    "<!-- s_num.append(s_num_2) -->\n",
    "<!-- print(\"s_num : \", s_num) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- En ayant une série avec un index numérique généré automatiquement : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- s = pd.Series([10, 2, 4]) -->\n",
    "<!-- s.append(pd.Series([2]), ignore_index=True) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- ### Pour un dataframe -->\n",
    "\n",
    "<!-- Reprenons notre dataframe : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"ville\" : [\"Marseille\", \"Aix\", -->\n",
    "<!--                    \"Marseille\", \"Aix\", \"Paris\", \"Paris\"], -->\n",
    "<!--         \"annee\": [2019, 2019, 2018, 2018,2019, 2019], -->\n",
    "<!--         \"x\": [1, 2, 2, 2, 0, 0], -->\n",
    "<!--         \"y\": [3, 3, 2, 1, 4, 4], -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Ajout d'une ligne dans un dataframe {#pandas-ajout-ligne-df} -->\n",
    "\n",
    "<!-- Comme pour une série, pour ajouter une ligne, on utlise la méthode `append()`. Dans un premier temps, créons un nouveau dataframe avec la ligne à ajouter : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- nv_ligne = pd.DataFrame([[\"Marseille\", \"2021\", 2, 4]], -->\n",
    "<!--                        columns = df.columns) -->\n",
    "<!-- print(\"nv_ligne : \\n\", nv_ligne) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On s'est assuré d'avoir le même nom de colonnes ici, en indiquant au paramètre `columns` de la méthode `pd.DataFrame` le nom des colonnes de `df`, c'est-à-dire `df.columns`. -->\n",
    "\n",
    "<!-- Ajoutons la nouvelle ligne à `df` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df = df.append(nv_ligne, ignore_index=True) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- À nouveau,la méthode `append()` appliquée à un dataframe, retourne une vue et n'affecte pas l'objet. -->\n",
    "\n",
    "\n",
    "<!-- On peut noter que lors de l'ajout d'une ligne, si le nom des colonnes n'est pas indiqué dans le même ordre que dans le dataframe dans lequel est effectué l'ajout, il faut rajouter une indication au paramètre `sort` de la méthode `append()` : -->\n",
    "\n",
    "<!-- - si `sort=True`, l'ordre des colonnes de la ligne ajoutée sera appliqué au dataframe de destination ; -->\n",
    "<!-- - si `sort=False`, l'odre des colonnes du dataframe de destination ne sera pas modifié. -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- nv_ligne = pd.DataFrame([[\"2021\", \"Marseille\", 2, 4]], -->\n",
    "<!--                        columns = [\"annee\", \"ville\", \"x\", \"y\"]) -->\n",
    "<!-- print(\"nv_ligne : \\n\", nv_ligne) -->\n",
    "<!-- print(\"avec sort=True : \\n\", -->\n",
    "<!--   df.append(nv_ligne, ignore_index=True, sort = True)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Ajout de plusieurs lignes dans un dataframe -->\n",
    "\n",
    "<!-- Pour ajouter plusieurs lignes, c'est exactement le même principe qu'avec une seule, il suffit juste d'ajouter un dataframe de plusieurs lignes, avec encore une fois les mêmes noms. -->\n",
    "\n",
    "<!-- Les lignes à insérer : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- nv_lignes = pd.DataFrame([ -->\n",
    "<!--     [\"Marseille\", \"2022\", 2, 4], -->\n",
    "<!--     [\"Aix\", \"2022\", 3, 3]], -->\n",
    "<!--     columns = df.columns) -->\n",
    "<!-- print(\"nv_ligne : \\n\", nv_lignes) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Puis l'insertion : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df = df.append(nv_lignes, ignore_index=True) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- #### Ajout d'une colonne dans un dataframe -->\n",
    "\n",
    "<!-- Pour ajouter une colonne dans un dataframe, on utilise la méthode `assign()`, en indiquant le nom et les valeurs. -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- from numpy import random -->\n",
    "<!-- df = df.assign(z = random.rand(len(df.index))) -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- #### Ajout de plusieurs colonnes dans un dataframe -->\n",
    "\n",
    "<!-- Pour ajouter plusieurs colonnes, le même principe s'applique : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df = df.assign(a = random.rand(len(df.index)), -->\n",
    "<!--           b = random.rand(len(df.index))) -->\n",
    "<!-- print(\"df : \\n\", df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- ## Retrait des valeurs dupliquées -->\n",
    "\n",
    "\n",
    "<!-- Pour retirer les valeurs dupliquées dans un dataframe, `NumPy` propose la méthode `drop_duplicates()`, qui prend plusieurs paramètres optionnels : -->\n",
    "\n",
    "<!-- - `subset` : en indiquant un ou plusieurs noms de colonnes, la recherche de doublons se fait uniquement sur ces colonnes ; -->\n",
    "<!-- - `keep` : permet d'indiquer quelle observation garder en cas de doublons identifies : -->\n",
    "\n",
    "<!--   - si `keep='first'`, tous les doublons sont retirés sauf la première occurrence, -->\n",
    "<!--   - si `keep='last'`, tous les doublons sont retirés sauf la dernière occurrence, -->\n",
    "<!--   -si `keep='False'`, tous les doublons sont retirés ; -->\n",
    "\n",
    "<!-- - `inplace` : booléen (défaut : `False`) pour indiquer si le retrait des doublons doit s'effectuer sur le dataframe ou bien si une copie doit être retournée (par défaut). -->\n",
    "\n",
    "\n",
    "<!-- Donnons quelques exemples à l'aide de ce dataframe qui compose deux doublons quand on considère sa totalité. Si on se concentre uniquement sur les années ou les villes, ou les deux, d'autres doublons peuvent être identifiés. -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"ville\" : [\"Marseille\", \"Aix\", -->\n",
    "<!--                    \"Marseille\", \"Aix\", \"Paris\", \"Paris\"], -->\n",
    "<!--         \"annee\": [2019, 2019, 2018, 2018,2019, 2019], -->\n",
    "<!--         \"x\": [1, 2, 2, 2, 0, 0], -->\n",
    "<!--         \"y\": [3, 3, 2, 1, 4, 4], -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour retirer les doublons : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.drop_duplicates()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Retirer les doublons en gardant la dernière valeur des doublons identifiés : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.drop_duplicates(keep='last') -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour retirer les doublons identifiés quand on se concentre sur le nom des villes, et en conservant uniquement la première valeur : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.drop_duplicates(subset = [\"ville\"], keep = 'first')) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Idem mais en se concentrant sur les couples (ville, annee) -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.drop_duplicates(subset = [\"ville\", \"annee\"], keep = 'first')) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- On note que le dataframe original n'a pas été impacté, puisque nous n'avons pas touché au paramètre `inplace`. Si à présent, nous demandons à ce que les changement soient opérés sur le dataframe plutôt que de récupérer une copie : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.drop_duplicates(subset = [\"ville\", \"annee\"], keep = 'first', inplace = True) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour savoir si une valeur est dupliquée dans un dataframe, `NumPy` propose la méthode `duplicated()`, qui retourne un masque indiquant pour chaque observation, si elle est dupliquée ou non. Son fonctionnement est similaire à `df.drop_duplicates()`, hormis pour le paramètre `inplace` qui n'est pas présent. -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.duplicated(subset = [\"ville\"], keep = 'first')) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On peut utiliser la méthode `any()` par la suite pour savoir s'il existe des doublons : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.duplicated(subset = [\"ville\"], keep = 'first').any()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- ## Opérations -->\n",
    "\n",
    "<!-- Il est souvent nécessaire de devoir effectuer des opérations sur les colonnes d'un dataframe, notamment lorsqu'il s'agit de créer une nouvelle variable. -->\n",
    "\n",
    "<!-- En reprenant les principes de modification de colonnes (c.f. Section\\ \\@ref(#pandas-ajout-valeurs)), on imagine assez facilement qu'il est possible d'appliquer les fonctions et méthodes de `NumPy` (c.f. Section\\ \\@ref(numpy-tableaux)) sur les valeurs des colonnes. -->\n",
    "\n",
    "<!-- Par exemple, considérons le dataframe suivant : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"height\" : -->\n",
    "<!--                [58, 59, 60, 61, 62, -->\n",
    "<!--                 63, 64, 65, 66, 67, -->\n",
    "<!--                 68, 69, 70, 71, 72], -->\n",
    "<!--         \"weight\": -->\n",
    "<!--                [115, 117, 120, 123, 126, -->\n",
    "<!--                 129, 132, 135, 139, 142, -->\n",
    "<!--                 146, 150, 154, 159, 164] -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(df) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Ajoutons la colonne `height_2`, élevant les valeurs de la colonne `height` au carré : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df = df.assign(height_2 = df.height**2) -->\n",
    "<!-- print(df.head(3)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- À présent, ajoutons la colonne `imc`, fournissant les valeurs de l'indicateur de masse corporelle pour les individus du dataframe ($\\text{IMC} = \\frac{\\text{weight}}{\\text{height}^2}$) : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df = df.assign(imc = df.weight / df.height_2) -->\n",
    "<!-- print(df.head(3)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ### Statistiques {pandas-statistiques-df} -->\n",
    "\n",
    "<!-- `pandas` propose quelques méthodes pour effectuer des statistiques descriptives pour chaque colonne ou par ligne. Pour cela, la syntaxe est la suivante (tous les paramètres ont une valeur par défaut, la liste est simplifiée ici) : -->\n",
    "\n",
    "<!-- ```{python, eval=F, echo=TRUE, error=TRUE} -->\n",
    "<!-- dataframe.fonction_stat(axis, skipna) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- - `axis` : 0 pour les lignes, 1 pour les colonnes ; -->\n",
    "<!-- - `skipna` : si `True`, exclue les valeurs manquantes pour effectuer les calculs. -->\n",
    "\n",
    "<!-- Parmi les méthodes disponibles : -->\n",
    "<!-- - `mean()` : moyenne ; -->\n",
    "<!-- - `mode()` : mode ; -->\n",
    "<!-- - `median()` : médiane ; -->\n",
    "<!-- - `std()` : écart-type ; -->\n",
    "<!-- - `min()` : minimum ; -->\n",
    "<!-- - `max()` : maximum -->\n",
    "<!-- - `mad()` : écart absolu à la moyenne ; -->\n",
    "<!-- - `sum()` : somme des valeurs ; -->\n",
    "<!-- - `prod()` : produit de tous les éléments ; -->\n",
    "<!-- - `count()` : comptage du nombre d'éléments. -->\n",
    "\n",
    "\n",
    "<!-- Par exemple, pour calculer la moyenne des valeurs pour chaque colonne : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"height\" : [58, 59, 60, 61, 62], -->\n",
    "<!--         \"weight\": [115, 117, 120, 123, 126], -->\n",
    "<!--         \"age\": [28, 33, 31, 31, 29], -->\n",
    "<!--         \"taille\": [162, 156, 172, 160, 158], -->\n",
    "<!--         \"married\": [True, True, False, False, True], -->\n",
    "<!--         \"city\": [\"A\", \"B\", \"B\", \"B\", \"A\"] -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- print(df.mean()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Si on le souhaite, on peut faire la moyenne des valeurs en colonne (sans aucun sens ici) : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.mean(axis=1)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Ces fonctions peuvent s'appliquer sur une seule colonne. Par exemple, pour afficher la valeur minimum : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"min : \", df.height.min()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Il est aussi utile de pouvoir obtenir la position des valeurs min et max ; ce qu'on peut obtenir avec les méthodes `idxmin()` et `idxmax()`, respectivement. -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"pos min : \", df.height.idxmin()) -->\n",
    "<!-- print(\"pos min : \", df.height.idxmax()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Une méthode très pratique est `describe()`, elle permet de retourner des statistiques descriptives sur l'ensemble des colonnes numériques : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(df.describe()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- ## Tri -->\n",
    "\n",
    "<!-- Il est aisé de trier un dataframe par ordre croissant ou décroissant d'une ou plusieurs de ses colonnes. Pour ce faire, on utilise la méthode `sort_values()`. La syntaxe est la suivante : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- DataFrame.sort_values(by, axis=0, ascending=True, -->\n",
    "<!--                       inplace=False, kind=\"quicksort\", -->\n",
    "<!--                       na_position=\"last\") -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- - `by` : nom ou liste de nom de la ou les colonnes utilisées pour effectuer le tri ; -->\n",
    "<!-- - `axis` : `0` pour l'index (par défaut), `1` pour les colonnes -->\n",
    "<!-- - `ascending` : booléen ou liste de booléens, quand `True` le tri est fait par valeurs croissantes (par défaut), quand `False` il est effectué par valeurs décroissantes -->\n",
    "<!-- - `inplace` : si `True`, le tri affecte le dataframe, sinon il retourne une vue ; -->\n",
    "<!-- - `kind` : choix de l'algorithme de tri (`quicksort` (par défaut), `mergesort`, `heapsort`) ; -->\n",
    "<!-- - `na_position` : si `first`, les valeurs manquantes sont placées au début ; si `last` (par défaut), à la fin. -->\n",
    "\n",
    "\n",
    "<!-- Donnons quelques exemples : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- dico = {\"height\" : [58, 59, 60, 61, 62], -->\n",
    "<!--         \"weight\": [115, np.nan, 120, 123, 126], -->\n",
    "<!--         \"age\": [28, 33, 31, 31, 29], -->\n",
    "<!--         \"taille\": [162, 156, 172, 160, 158], -->\n",
    "<!--         \"married\": [True, True, np.nan, False, True], -->\n",
    "<!--         \"city\": [\"A\", \"B\", \"B\", \"B\", \"A\"] -->\n",
    "<!--        } -->\n",
    "<!-- df = pd.DataFrame(dico) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Si on trie les valeurs par ordre décroissant des valeurs de la colonne `height` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.sort_values(by=\"height\", ascending=False) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour effectuer un tri par ordre croissant des valeurs de `married` (rappel, `True` est interprété comme 1 et `False` comme 0), puis décoissant de `weight`, en plaçant les valeurs `NaN` en premier : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- df.sort_values(by=[\"married\", \"weight\"], -->\n",
    "<!--                ascending=[True, False], -->\n",
    "<!--                na_position=\"first\") -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- On note que les valeurs `NaN` sont remontées en avant pour les sous-groupes composés en fonction des valeurs de `married`. -->\n",
    "\n",
    "\n",
    "<!-- ## Concaténation -->\n",
    "\n",
    "<!-- Il est fréquent d'avoir des données en provenance de plusieurs sources lorsque l'on réalise une analyse. Il est alors nécessaire de pouvoir combiner les différentes sources dans une seule. Dans cette section, nous allons nous contenter de concaténer différents dataframes entre-eux, dans des cas simples dans lesquels on sait *a priori* qu'il suffit de coller deux dataframes côte-à-côte ou l'un en-dessous de l'aure. Le cas des jointures un peu plus élaborées avec appariement en fonction d'une ou plusieurs colonnes est abordé dans la Section\\ \\@ref(pandas-jointures). -->\n",
    "\n",
    "\n",
    "<!-- Dans un premier temps, créons deux dataframes avec le même nombre de lignes : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- x_1 = pd.DataFrame(np.random.randn(5, 4), -->\n",
    "<!--                    columns=[\"a\", \"b\", \"c\", \"d\"]) -->\n",
    "<!-- x_2 = pd.DataFrame(np.random.randn(5, 2), -->\n",
    "<!--                    columns = [\"e\", \"f\"]) -->\n",
    "<!-- print(\"x_1 : \\n\", x_1) -->\n",
    "<!-- print(\"\\nx_2 : \\n\", x_2) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Pour \"coller\" le dataframe `x_2` à droite de `x_1`, on peut utiliser la méthode `concat()` de `pandas`. Pour indiquer que la concaténation s'effectue sur les colonnes, on précise la valeur `1` pour le paramètre `axix` comme suit : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(pd.concat([x_1, x_2], axis = 1)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour coller les dataframes les uns en-dessous des autres, on peut utiliser la méthode `append()`, comme indiqué dans la Section\\ \\@ref(pandas-ajout-ligne-df), ou on peut aussi utiliser la méthode `concat()`. -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- x_3 = pd.DataFrame(np.random.randn(5, 2), -->\n",
    "<!--                    columns = [\"e\", \"f\"]) -->\n",
    "<!-- print(\"x_3 : \\n\", x_3) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Rajoutons les observations de `x_3` en-dessous de celles de `x_2` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(pd.concat([x_2, x_3], axis = 0)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Comme on peut le voir, l'indice des lignes de `x_2` n'a pas été modifié. Si on souhaite qu'il le soit, on peut le préciser via le paramètre `ignore_index` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(pd.concat([x_2, x_3], axis = 0, ignore_index=True)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Si le nom des colonnes n'est pas ientique, des valeurs `NaN` seront introduites : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- x_4 = pd.DataFrame(np.random.randn(5, 2), -->\n",
    "<!--                    columns = [\"e\", \"g\"]) -->\n",
    "<!-- print(\"x_4 : \\n\", x_4) -->\n",
    "<!-- pd.concat([x_2, x_4], axis = 0, sort=False, ignore_index=True) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- ## Jointures {#pandas-jointures} -->\n",
    "\n",
    "<!-- Il est plus fréquent d'avoir recours à des jointures un peu plus élaborées pour rassembler les différentes sources de données en une seule. `pandas` offre un moyen performant pour rassembler les données, la fonction `merge()`. -->\n",
    "\n",
    "\n",
    "<!-- Pour illustrer les différentes jointures de cette section, créons quelques dataframes : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- exportations_fr = pd.DataFrame( -->\n",
    "<!--     {\"country\" : \"France\", -->\n",
    "<!--      \"year\" : np.arange(2014, 2017), -->\n",
    "<!--      \"exportations\" : [816.8192172, 851.6632573, 867.4014253] -->\n",
    "<!--     }) -->\n",
    "\n",
    "<!-- importations_fr = pd.DataFrame( -->\n",
    "<!--     {\"country\" : \"France\", -->\n",
    "<!--      \"year\" : np.arange(2015, 2018), -->\n",
    "<!--      \"importations\" : [898.5242962, 936.3691166, 973.8762149] -->\n",
    "<!--     }) -->\n",
    "\n",
    "<!-- exportations_us = pd.DataFrame( -->\n",
    "<!--     {\"country\" : \"USA\", -->\n",
    "<!--      \"year\" : np.arange(2014, 2017), -->\n",
    "<!--      \"exportations\" : [2208.678084, 2217.733347, 2210.442218] -->\n",
    "<!--     }) -->\n",
    "\n",
    "<!-- importations_us = pd.DataFrame( -->\n",
    "<!--     {\"country\" : \"USA\", -->\n",
    "<!--      \"year\" : np.arange(2015, 2018), -->\n",
    "<!--      \"importations\" : [2827.336251, 2863.264745, np.nan] -->\n",
    "<!--     }) -->\n",
    "\n",
    "<!-- importations_maroc = pd.DataFrame( -->\n",
    "<!--     {\"pays\" : \"Maroc\", -->\n",
    "<!--      \"annee\" : np.arange(2015, 2018), -->\n",
    "<!--      \"importations\" : [46.39884177, 53.52375588, 56.68165748] -->\n",
    "<!--     }) -->\n",
    "<!-- exportations_maroc = pd.DataFrame( -->\n",
    "<!--     {\"country\" : \"Maroc\", -->\n",
    "<!--      \"year\" : np.arange(2014, 2017), -->\n",
    "<!--      \"exportations\" : [35.50207915, 37.45996653, 39.38228396] -->\n",
    "<!--     }) -->\n",
    "\n",
    "<!-- exportations = pd.concat([exportations_fr, exportations_us], ignore_index=True) -->\n",
    "<!-- importations = pd.concat([importations_fr, importations_us], ignore_index=True) -->\n",
    "\n",
    "<!-- print(\"exportations : \\n\", exportations) -->\n",
    "<!-- print(\"\\nimportations : \\n\", importations) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- La fonction `merge()` de `pandas` nécessite de préciser la table de gauche (que l'on appellera ici `x`) via le paramètre `left` sur qui viendra s'effectuer la jointure de la table de droite (que l'on appellera ici `y`) via le paramètre `right`. -->\n",
    "\n",
    "<!-- Par défaut, la fonction `merge()` réalise une jointure de type `inner`, c'est-à-dire que toutes les toutes les lignes de `x` qui trouvent une correspondance dans `y`, et toutes les colonnes de `x` et `y` seront dans le résultat de la jointure : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(pd.merge(left = importations, right = exportations)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Si on désire changer le type de jointure, on peut modifier la valeur du paramètre `how` de la fonction `merge()`, pour lui donner une des valeurs suivantes : -->\n",
    "\n",
    "<!-- - `left` : toutes les lignes de `x`, et toutes les colonnes de `x` et `y`. Les lignes dans `x` pour lesquelles il n'y a pas de correspondance dans `y` auront des valeurs `NaN` dans les -->\n",
    "<!-- nouvelles colonnes. S'il y a plusieurs correspondances dans les noms entre `x` et `y`, toutes -->\n",
    "<!-- les combinaisons sont retournées ; -->\n",
    "<!-- - `inner` :  toutes les lignes de `x` pour lesquelles il y a des valeurs correspondantes dans `y`, et toutes les colonnes de `x` et `y`. S'il y a plusieurs correspondances dans les noms -->\n",
    "<!-- entre `x` et `y`, toutes les combinaisons possibles sont retournées ; -->\n",
    "<!-- - `right` : toutes les lignes de `y`, et toutes les colonnes de `y` et `x`. Les lignes dans -->\n",
    "<!-- `y` pour lesquelles il n'y a pas de correspondance dans `x` auront des valeurs `NaN` dans les -->\n",
    "<!-- nouvelles colonnes. S'il y a plusieurs correspondances dans les noms entre `y` et `x`, toutes -->\n",
    "<!-- les combinaisons sont retournées ; -->\n",
    "<!-- - `outer`: toutes les lignes de `x` et de `y`, et toutes les colonnes de `x` et `y`. Les lignes de `x` pour lesquelles il n'y a pas de correspondance dabs `y` et celles de `y` pour lesquelles il n'y a pas de correspondance dans `x` auront des valeurs `NaN`. -->\n",
    "\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(\"left : \\n\", pd.merge(left = importations, right = exportations, how=\"left\")) -->\n",
    "<!-- print(\"\\nright : \\n\", pd.merge(left = importations, right = exportations, how=\"right\")) -->\n",
    "<!-- print(\"\\nouter : \\n\", pd.merge(left = importations, right = exportations, how=\"outer\")) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Le paramètre `on`, qui attend un nom de colonne ou une liste de noms sert à désigner les colonnes permettant de faire la jointure. Les noms de colonnes doivent être identiques dans les deux dataframes. -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(pd.merge(left = importations, right = exportations, on = \"country\")) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Si le nom des colonnes devant servir à réaliser la jointure sont différents entre le dataframe de gauche et celui de droite, on indique au paramètre `left_on` le ou les noms de colonnes du dataframe de gauche à utiliser pour la jointure ; et au paramètre `right_on`, le ou les noms correspondants dans le dataframe de doite : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- pd.merge(left = importations_maroc, right = exportations_maroc, -->\n",
    "<!--          left_on= [\"pays\", \"annee\"], right_on = [\"country\", \"year\"] ) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Avec le paramètre `suffixes`, on peut définir des suffixes à ajouter aux noms des colonnes lorsqu'il existe des colonnes dans `x` et dans `y` portant le même nom mais ne servant pas à la jointure. Par défaut, les suffixes (`_x` et `_y`) sont rajoutés. -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(pd.merge(left = importations, right = exportations, -->\n",
    "<!--                on = \"country\", -->\n",
    "<!--                suffixes=(\"_gauche\", \"_droite\")).head(3)) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ## Agrégation -->\n",
    "\n",
    "<!-- Il arrive de vouloir agréger les valeurs d'une variable, pour passer par exemple d'une dimension -->\n",
    "<!-- trimestrielle à annuelle. Avec des observations spatiales, cela peut aussi être le cas, comme -->\n",
    "<!-- par exemple lorsque l'on dispose de données à l'échelle des départements et que l'on souhaite -->\n",
    "<!-- connaître les valeurs agrégées à l'échelle des régions. -->\n",
    "\n",
    "<!-- Pour illustrer les différentes opérations d'agrégation, créons un dataframe avec des des données de chômage dans différentes régions, départements et années : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chomage = pd.DataFrame( -->\n",
    "<!--     {\"region\" : ([\"Bretagne\"]*4 + [\"Corse\"]*2)*2, -->\n",
    "<!--      \"departement\" : [\"Cotes-d'Armor\", \"Finistere\", -->\n",
    "<!--                       \"Ille-et-Vilaine\", \"Morbihan\", -->\n",
    "<!--                       \"Corse-du-Sud\", \"Haute-Corse\"]*2, -->\n",
    "<!--      \"annee\" : np.repeat([2011, 2010], 6), -->\n",
    "<!--      \"ouvriers\" : [8738, 12701, 11390, 10228, 975, 1297, -->\n",
    "<!--                    8113, 12258, 10897, 9617, 936, 1220], -->\n",
    "<!--      \"ingenieurs\" : [1420, 2530, 3986, 2025, 259, 254, -->\n",
    "<!--                      1334, 2401, 3776, 1979, 253, 241] -->\n",
    "<!--     }) -->\n",
    "<!-- print(chomage) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Comme nous l'avons vu précédemment (c.f. Section\\ \\@ref(pandas-statistiques-df)), on peut utiliser des méthodes permettant de calculer des statistiques simples sur l'ensemble des données. Par exemple, pour afficher la moyenne de chacune des colonnes numériques : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(chomage.mean()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Ce qui nous intéresse dans cette section, est d'effectuer des calculs sur des sous-groupes de données. Le principe est simple : dans un premier temps, on sépare les données en fonction de groupes identifiés (*split*), puis on applique une opération sur chacun des groupes (*apply*), et enfin on rassemble les résultats (*combine*). Pour effectuer le regroupement, en fonction de facteurs avant d'effectuer les calculs d'agrégation, `pandas` propose la méthode `groupby()`. On lui fournit en paramètre le ou les noms de colonnes servant à effectuer les groupes. -->\n",
    "\n",
    "<!-- ### Agrégation selon les valeurs d'une seule colonne -->\n",
    "\n",
    "<!-- Par exemple, admettons que nous souhaitons obtenir le nombre total de chomeurs ouvriers par année. Dans un premier temps, on utilise la méthode `groupby()` sur notre dataframe en indiquant que les groupes doivent être créés selon les valeurs de la colonne `annee` -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(chomage.groupby(\"annee\")) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Ensuite, on récupère la variable `ouvriers` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(chomage.groupby(\"annee\").annee) -->\n",
    "<!-- # Ou bien -->\n",
    "<!-- print(chomage.groupby(\"annee\")[\"annee\"]) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Et enfin, on peut effectuer le calcul sur chaque sous-groupe et afficher le résultat : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- print(chomage.groupby(\"annee\")[\"ouvriers\"].sum()) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Si on veut effectuer ce calcul pour plusieurs colonnes, par exemple `ouvriers` et `ingenieurs`, il suffit de sélectionner *a priori* la variale de regroupement et les variables pour lesquelles on désire effectuer le calcul : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chomage.loc[:,[\"annee\", \"ouvriers\", \"ingenieurs\"]].groupby(\"annee\").sum() -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- ### Agrégation selon les valeurs de plusieurs colonnes -->\n",
    "\n",
    "<!-- À présent, admettons que l'on souhaite effectuer une agrégation en fonction de l'année et de la région. Il s'agit simplement de donner une liste contenant les noms des colonnes utilisées pour créer les différents groupes : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chomage.loc[:,[\"annee\", \"region\", -->\n",
    "<!--                \"ouvriers\", \"ingenieurs\"]].groupby([\"annee\", -->\n",
    "<!--                                                    \"region\"]).sum() -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- ## Stacking et unstacking -->\n",
    "\n",
    "\n",
    "<!-- À compléter -->\n",
    "\n",
    "\n",
    "<!-- ## Exportation et importation de données -->\n",
    "\n",
    "<!-- `pandas` offre de nombreuses fonctions pour importer et exporter des données dans différents formats. -->\n",
    "\n",
    "\n",
    "<!-- ### Exportation des données -->\n",
    "\n",
    "\n",
    "<!-- #### Exportation de données tabulaires -->\n",
    "\n",
    "\n",
    "<!-- ##### Vers un fichier CSV {pandas-export_csv} -->\n",
    "\n",
    "\n",
    "<!-- Pour exporter des données tabulaires, comme celles contenues dans un dataframe, `NumPy` propose la méthode `to_csv()`, qui accepte de nombreuses spécifications. Regardons quelques-unes d'entre-elles qui me semblent les plus courantes : -->\n",
    "\n",
    "<!-- | Paramètre | Description | -->\n",
    "<!-- | ---------------: | -------------------------------------------------: | -->\n",
    "<!-- | `path_or_buf` | chemin vers le fichier | -->\n",
    "<!-- | `sep` | caractère de séparation des champs | -->\n",
    "<!-- | `decimal` | Caractère à utiliser pour le séparateur de décimales | -->\n",
    "<!-- | `na_rep` | représentation à utiliser pour les valeurs manquantes | -->\n",
    "<!-- | `header` | indique si le nom des colonnes doit être exporté (`True` par défaut) | -->\n",
    "<!-- | `index` | indique si le nom des lignes doit être exporté (`True` par défaut) | -->\n",
    "<!-- | `mode` | mode d'écriture python (c.f. Tableau\\ \\@ref(tab:open-mode-ouverture), par défaut `w`) | -->\n",
    "<!-- | `encoding` | encodage des caractères (`utf-8` par défaut) | -->\n",
    "<!-- | `compression` | compression à utiliser pour le fichier de destination (`gzip`, `bz2`, `zip`,  `xz`) | -->\n",
    "<!-- | `line_terminator` | caractère de fin de ligne | -->\n",
    "<!-- | `quotechar` | Caractère utilisé pour mettre les champs entre *quotes* | -->\n",
    "<!-- | `chunksize` | (entier) nombre de lignes à écrire à la fois | -->\n",
    "<!-- | `date_format` | format de dates pour les objets `datetime` | -->\n",
    "\n",
    "<!-- Table: (#tab:pandasto-csv) Paramètres principaux de la fonction `to_csv` -->\n",
    "\n",
    "<!-- Admettons que nous souhaitons exporter le contenu du dataframe `chomage` vers un fichier CSV dont les champs sont séparés par des points-virgules, et en n'exportant pas l'index : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chomage = pd.DataFrame( -->\n",
    "<!--     {\"region\" : ([\"Bretagne\"]*4 + [\"Corse\"]*2)*2, -->\n",
    "<!--      \"departement\" : [\"Cotes-d'Armor\", \"Finistere\", -->\n",
    "<!--                       \"Ille-et-Vilaine\", \"Morbihan\", -->\n",
    "<!--                       \"Corse-du-Sud\", \"Haute-Corse\"]*2, -->\n",
    "<!--      \"annee\" : np.repeat([2011, 2010], 6), -->\n",
    "<!--      \"ouvriers\" : [8738, 12701, 11390, 10228, 975, 1297, -->\n",
    "<!--                    8113, 12258, 10897, 9617, 936, 1220], -->\n",
    "<!--      \"ingenieurs\" : [1420, 2530, 3986, 2025, 259, 254, -->\n",
    "<!--                      1334, 2401, 3776, 1979, 253, 241] -->\n",
    "<!--     }) -->\n",
    "<!-- print(chomage) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Pour l'exportation : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chemin = \"./fichiers_exemples/chomage.csv\" -->\n",
    "<!-- chomage.to_csv(chemin, decimal=\";\", index=False) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- Si on désire que le fichier CSV soit compressé dans un fichier `gzip`, on le nomme avec l'extention `.csv.gz` et on ajoute la valeur `gzip` au paramètre `compression` : -->\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chemin = \"./Python_pour_economistes/fichiers_exemples/chomage.csv.gz\" -->\n",
    "<!-- chomage.to_csv(chemin, decimal=\";\", index=False, compression=\"gzip\") -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ##### Vers un fichier HDF5 -->\n",
    "\n",
    "\n",
    "<!-- Pour enregistrer les données d'un dataframe dans un fichier HDF5 utilisant HDFStore, `pandas` propose la méthode `to_hdf()` qui fonctionne de la même manière que la fonction `to_csv()` (cf. Section\\ \\@ref(pandas-export_csv)). -->\n",
    "\n",
    "<!-- Il est nécessaire de spécifier le paramètre `path_or_buf` pour indiquer le chemin et le paramètre `key` pour identifier l'objet à enregistrer dans le fichier. -->\n",
    "\n",
    "<!-- La syntaxe est la suivante : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chemin = \"./fichiers_exemples/chomage.h5\" -->\n",
    "<!-- chomage.to_hdf(chemin, \"base_chomage\", decimal=\";\", index=False) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ## Importation des données -->\n",
    "\n",
    "<!-- `pandas` propose de nombreuses fonctions pour importer des données. Dans cette version des notes de cours, nous allons en aborder 3 : `read_csv()`, pour lire des fichiers CSV ; `read_excel()`, pour lire des fichiers Excel ; et `read_hdf()` pour lire des fichiers HDF5. -->\n",
    "\n",
    "<!-- Dans la prochaine version, des ajouts sur `read_html()`, `read_fwf()`, `read_stata()`, `read_json()`. -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- ### Fichiers CSV {#pandas-importation-csv} -->\n",
    "\n",
    "\n",
    "<!-- Pour importer des données depuis un fichier CSV, `pandas` propose la fonction `read_csv()` : -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chemin = \"./fichiers_exemples/chomage.csv\" -->\n",
    "<!-- chomage = pd.read_csv(chemin, decimal=\";\", index=False) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Il est possible de fournir une URL pointant vers un fichier CSV comme chemin, la fonction `read_csv()`. -->\n",
    "\n",
    "<!-- Parmi les paramètres que l'on utilise fréquemment : -->\n",
    "\n",
    "<!-- - `sep`, `delimiter` : séparateur de champs ; -->\n",
    "<!-- - `decimal` : séparateur de décimales ; -->\n",
    "<!-- - `header` : numéro(s) de ligne(s) à utiliser comme en-tête des données ; -->\n",
    "<!-- - `skiprows` : numéro(s) de ligne(s) à sauter au début ; -->\n",
    "<!-- - `skipfooter` : numéro(s) de ligne(s) à sauter à la fin ; -->\n",
    "<!-- - `nrows` : nombre de ligne à lire ; -->\n",
    "<!-- - `na_values` : chaînes de caractères supplémentaires à considérer comme valeurs manquantes (en plus de `#N/A`, `#N/A N/A`, `#NA`, `-1.#IND`, `-1.#QNAN`, `-NaN`, `-nan`, `1.#IND`, `1.#QNAN`, `N/A`, `NA`, `NULL`, `NaN`, `n/a`, `nan`, `null`) ; -->\n",
    "<!-- - `quotechar` : caractère de *quote* ; -->\n",
    "<!-- - `encoding` : encodage des caractères (défaut `utf-8`). -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- ### Fichiers Excel {#pandas-importation-excel} -->\n",
    "\n",
    "<!-- Pour importer des fichiers Excel, `pandas` propose la fonction `read_excel()`. -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chemin = \"./fichiers_exemples/chomage.xlsx\" -->\n",
    "<!-- chomage = pd.read_excel(chemin, skiprows=2, header=1, sheet = 1) -->\n",
    "<!-- print(chomage) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "<!-- Parmi les paramètres fréquemment utilisés : -->\n",
    "\n",
    "<!-- - `header` : numéro de ligne à utiliser comme en-tête ; -->\n",
    "<!-- - `sheet` : nom ou numéro de feuille ; -->\n",
    "<!-- - `skiprows` : nombre de lignes à sauter au début ; -->\n",
    "<!-- - `thousands` : séparateur de milliers. -->\n",
    "\n",
    "\n",
    "<!-- ### Fichiers HDF5 {#pandas-importation-hdf} -->\n",
    "\n",
    "<!-- ```{python, eval=T, echo=TRUE, error=TRUE} -->\n",
    "<!-- chemin = \"./fichiers_exemples/chomage.h5\" -->\n",
    "<!-- print(pd.read_hdf(chemin, \"base_chomage\")) -->\n",
    "<!-- ``` -->\n",
    "\n",
    "\n",
    "<!-- ## Exercice -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- **Exercice 1 : Importation et exportation** -->\n",
    "\n",
    "<!-- 1. Télécharger à la main le fichier csv à l'adresse suivante : http://egallic.fr/Enseignement/Python/Exercices/donnees/notes.csv et le placer dans le répertoire courant. Importer son contenu dans Python. -->\n",
    "<!-- 2. Importer à nouveau les données dans Python, mais en fournissant cette fois le l’url directement à la fonction d'importation. -->\n",
    "<!-- 3. À présent, importer le contenu du fichier disponible à l’adresse http://egallic.fr/Enseignement/Python/Exercices/donnees/notes_decim.csv. Le séparateur de champs est un point virgule -->\n",
    "<!-- et le séparateur décimal est une virgule. -->\n",
    "<!-- 4. Importer le contenu du fichier http://egallic.fr/Enseignement/Python/Exercices/donnees/notes_h.csv. Le nom des colonnes n’est pas présent. -->\n",
    "<!-- 5. Importer le contenu du fichier http://egallic.fr/Enseignement/Python/Exercices/donnees/notes_h_s.csv. La première ligne n’est pas à importer. -->\n",
    "<!-- 6. Importer le contenu de la première feuille du fichier Excel http://egallic.fr/Enseignement/Python/Exercices/donnees/notes.xlsx. -->\n",
    "<!-- 7. Importer le contenu de la seconde feuille (`notes_h_s`) du fichier Excel disponible ici : http://egallic.fr/Enseignement/Python/Exercices/donnees/notes.xlsx. La première ligne est un commentaire à ne pas considérer durant l’importaiton. -->\n",
    "<!-- 8. Exporter le contenu de l’objet contenant les notes de la question précédente au format csv (virgule -->\n",
    "<!-- en séparateur de champs, point en séparateur décimal, ne pas conserver le numéro des -->\n",
    "<!-- lignes). -->\n",
    "\n",
    "\n",
    "<!-- **Exercice 2 : Manipulation de tableaux de données** -->\n",
    "\n",
    "<!-- 1. À l'aide de la fonction `read_excel()` de la librairie `pandas`, importer le contenu de la feuille intitulée `notes_2012` du fichier Excel disponible à l'adresse suivante : http://egallic.fr/Enseignement/Python/Exercices/donnees/notes_etudiants.xlsx et le stocker dans une variable que l'on nommera notes_2012. -->\n",
    "<!-- 2. Afficher les 6 premières lignes du jeu de données, puis les dimensions du tableau. -->\n",
    "<!-- 3. Conserver uniquement la colonne `note_stat` du tableau de données `notes_2012` dans un objet que l'on appellera `tmp`. -->\n",
    "<!-- 4. Conserver uniquement les colonnes `num_etudiant`, `note_stat` et `note_macro` dans un objet nommé `tmp`. -->\n",
    "<!-- 5. Remplacer le contenu de `tmp` par les observations de `notes_2012` pour lesquelles l'individu a obtenu une note de stat supérieure (strictement) à 10. -->\n",
    "<!-- 6. Remplacer le contenu de tmp par les observations de `notes_2012` pour lesquelles l'individu a obtenu une note de stats comprise dans l'intervalle (10, 15). -->\n",
    "<!-- 7. Regarder s'il y a des doublons dans le tableau de données `notees_2012` ; le cas échéant, les retirer du tableau. -->\n",
    "<!-- 8. Afficher le type des données de la colonne `num_etudiant`, puis afficher le type de toutes les colonnes de notes_2012. -->\n",
    "<!-- 9. Ajouter au tableau `notes_2012` les colonnes suivantes : -->\n",
    "\n",
    "<!--   (a) `note_stat_maj` : la note de stat (`note_stat`) majorée d'un point, -->\n",
    "<!--   (b) `note_macro_maj` : la note de macro (`note_macro`) majorée de trois points (le faire en deux étapes : d'abord deux points en plus, puis un point). -->\n",
    "<!-- 10. Renommer la colonne year en annee. -->\n",
    "<!-- 11. Depuis le fichier `notes_etudiants.xlsx` (c.f. question 1), importer le contenu des feuilles `notes_2013`, `notes_2014` et `prenoms` et le stocker dans les objets `notes_2013`, `notes_2014` et `prenoms`, respectivement. -->\n",
    "<!-- 12. Empiler le contenu des tableaux de données `notes_2012`, `notes_2013` et `notes_2014` dans un objet que l'on nommera `notes`. -->\n",
    "<!-- 13. Fusionner les tableaux `notes` et `prenoms` à l'aide d'une jointure gauche, de manière à rajouter les informations contenues dans le tableau prenoms aux observations de notes. La jointure doit se faire par le numéro d'étudiant et l'année, l'objet final viendra remplacer le contenu de notes. -->\n",
    "<!-- 14. Trier le tableau notes par années croissantes et notes de macro décroissantes. -->\n",
    "<!-- 15. Créer une colonne `apres_2012` qui prend la valeur `True` si l'observation concerne une note attribuée après 2012. -->\n",
    "<!-- 16. En effectuant des regroupements sur le dataframe `notes` calculer : -->\n",
    "\n",
    "<!--   (a) la moyenne et l'écart-type annuels des notes pour chacune des deux matières, -->\n",
    "<!--   (b) la moyenne et l'écart-type annuels et par sexe des notes pour chacune des deux matières. -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- # Visualisation de données -->\n",
    "\n",
    "\n",
    "<!-- https://seaborn.pydata.org/ -->\n",
    "<!-- <!-- # Programmation parallèle --> -->\n",
    "\n",
    "<!-- # References -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
